{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d7b071-3c52-4189-81e4-2fe25bb2f61d",
   "metadata": {},
   "source": [
    "# First Full LoRA Trial with Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ae5288-cc75-406e-a9a6-b998ab768462",
   "metadata": {},
   "source": [
    "## What We Are Doing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a0606-6a36-422d-8475-f2f23b06fdb0",
   "metadata": {},
   "source": [
    "Starting with going through what I've done as well as finishing the task of getting my LoRA-fine-tuned model from Hugging Face and running inference on it (i.e. testing it using the test set). \n",
    "\n",
    "Note that you'll need the following files in the working directory of the notebook, all available from the repo,\n",
    "\n",
    "https://github.com/bballdave025/rwkv-lora/tree/main\n",
    "\n",
    "```\n",
    "'following files'\n",
    "  dwb_rouge_scores.py\n",
    "  dwb_scoring_utils_rouge.py\n",
    "  dwb_text_utils_data_rep.py\n",
    "  samsum-test.csv\n",
    "  samsum-train.csv\n",
    "  samsum-validation.csv\n",
    "  system_info_as_script.py\n",
    "```\n",
    "\n",
    "If the conversion has already been done, feel free to just transfer\n",
    "\n",
    "```\n",
    "samsum-test.json\n",
    "samsum-train.json\n",
    "samsum-validation.json\n",
    "```\n",
    "\n",
    "without the `*.csv` files. These files come from https://www.kaggle.com/datasets/nileshmalode1/samsum-dataset-text-summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f39baae-6f26-417a-93b1-1aff242d1f1c",
   "metadata": {},
   "source": [
    "## peft (for LoRA) and FLAN-T5-small for the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa78dae-04c7-45b9-8b89-4484a40cad6c",
   "metadata": {},
   "source": [
    "I'm following what seems to be a great tutorial from Mehul Gupta,\n",
    "\n",
    "> https://medium.com/data-science-in-your-pocket/lora-for-fine-tuning-llms-explained-with-codes-and-example-62a7ac5a3578\n",
    "> \n",
    "> https://web.archive.org/web/20240522140323/https://medium.com/data-science-in-your-pocket/lora-for-fine-tuning-llms-explained-with-codes-and-example-62a7ac5a3578\n",
    "\n",
    "Well, I followed that for my first try. I've been making improvements. (I've been making it so it works.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38355dd4-1708-4975-9fcd-f2cf6265e638",
   "metadata": {},
   "source": [
    "## Starting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cac1b2-3a28-4036-b665-bfb756227cb6",
   "metadata": {},
   "source": [
    "I'm doing this to prepare creating a LoRA for RWKV ( links [here](#Notes-Looking-Forward-to-LoRA-on-RWKV) ) so as to fine-tune it for Pat's OLECT-LM stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab0319e-1d1e-4fa3-9153-e8c26344e652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721754308_20240723T170508-0600\n"
     ]
    }
   ],
   "source": [
    "# # Don't need this again\n",
    "#!powershell -c (Get-Date -UFormat \"%s_%Y%m%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8476aae1-0e49-4094-8eb8-6bf0d51acbc7",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`1721754308_20240723T170508-0600`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2a1051-3b8f-442b-85f2-c6609ce45369",
   "metadata": {},
   "source": [
    "## Installation - minimize it unless you need `!pip install` commands\n",
    "\n",
    "(Feel free to drop down to the [TL;DR](#Install-TL;DR) section.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f416a8f-31a2-4db5-8edb-73688c2af5d3",
   "metadata": {},
   "source": [
    "### Detailed stuff - minimize it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feb7cd9-7b21-42e8-a343-ff3585ea5a2d",
   "metadata": {},
   "source": [
    "#### Conda environment file - minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebd241c-2101-414c-ab68-7991b69b4f29",
   "metadata": {},
   "source": [
    "My <strike>`environment.yml` </strike> `environment-cpu.yml` file for a cpu (specifically, one run on Windows) will have its contents listed below. It should have everything needed for an install anywhere. To make things consistent for CoLab, I've put the `!pip install`s here. The fact that CoLab disconnects in the middle of jobs and only gives a little time with a GPU makes it (it=CoLab) not worth the trouble, but I like having the installs where I can see them. By the way, the directory should have a `full_environment-cpu.yml`, which includes everything for the environment on Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d596bcde-28a3-41a7-8ebf-3676c3005c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_want_to_read_realtime = False\n",
    "\n",
    "if do_want_to_read_realtime:\n",
    "    with open(\"environment-cpu.yml\", 'r', encoding='utf-8') as fh:\n",
    "        while True:\n",
    "            line = fh.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            ##endof:  if not line\n",
    "            print(line.replace(\"\\n\", \"\"))\n",
    "        ##endof:  while True\n",
    "    ##endof:  with open ... fh\n",
    "##endof:  if do_want_to_read_realtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d29c4f9-e5ff-4d18-872a-3c5d958c5723",
   "metadata": {},
   "source": [
    "For the CPU, I got the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49530485-e077-49bb-a5ff-a6fa3bf4cb0c",
   "metadata": {},
   "source": [
    "```\n",
    "###############################################\n",
    "#  Now used for\n",
    "#+     'full_environment.yml'\n",
    "#+   which has everything, including \n",
    "#+   platform-specific stuff (Windows, here)\n",
    "#+ AND\n",
    "#+     'environment.yml'\n",
    "#+   a meant-to-be OS-agnostic package list\n",
    "#======\n",
    "\n",
    "# @file: environment-cpu.yml\n",
    "# @since 2024-07-25\n",
    "## 1721754699_2024-07-23T17:11:39-0600\n",
    "## IMPORTANT NOTES\n",
    "##\n",
    "##  A couple of installations were made from git repos. (These next commands\n",
    "##+ were the originals - look below for the commands needed for \n",
    "##+ reproducibility.)\n",
    "##     >pip install git+https://github.com/huggingface/peft.git\n",
    "##     >pip install git+https://github.com/nexplorer-3e/qwqfetch\n",
    "##\n",
    "##  The commit info will be important for reproducibility.\n",
    "##\n",
    "##-----\n",
    "##  qwqfetch   for system info\n",
    "##\n",
    "##   Resolved https://github.com/nexplorer-3e/qwqfetch \\\n",
    "##       to commit f72d222e2fff5ffea9f4e4b3a203e4c4d9e8cf00\n",
    "##   Successfully installed qwqfetch-0.0.0\n",
    "##\n",
    "##  !!!!! So, the command should be !!!!!\n",
    "##\n",
    "## (Windows CMD)\n",
    "##>pip install git+https://github.com/huggingface/qwqfetch.git@^\n",
    "## e7b75070c72a88f0f7926cc6872858a2c5f0090d\n",
    "##\n",
    "## (Windows PowerShell)\n",
    "##>pip install git+https://github.com/huggingface/qwqfetch.git@`\n",
    "## e7b75070c72a88f0f7926cc6872858a2c5f0090d\n",
    "##\n",
    "## (*NIX-like)\n",
    "##$ pip install git+https://github.com/huggingface/qwqfetch.git@\\\n",
    "##  e7b75070c72a88f0f7926cc6872858a2c5f0090d\n",
    "##  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "##-----\n",
    "##  peft: I installed PEFT among other things, but I'm picking out \n",
    "##+       stuff relevant to peft. PEFT has LoRA in it.\n",
    "##\n",
    "##   Resolved https://github.com/huggingface/peft.git \\\n",
    "##       to commit e7b75070c72a88f0f7926cc6872858a2c5f0090d\n",
    "##   Successfully built peft\n",
    "##\n",
    "##  !!!!! So, the command should be !!!!!\n",
    "## (Windows CMD)\n",
    "##>pip install git+https://github.com/huggingface/peft.git@^\n",
    "## e7b75070c72a88f0f7926cc6872858a2c5f0090d\n",
    "##\n",
    "## (Windows PowerShell)\n",
    "##>pip install git+https://github.com/huggingface/peft.git@`\n",
    "## e7b75070c72a88f0f7926cc6872858a2c5f0090d\n",
    "##\n",
    "## (*NIX-like)\n",
    "##$ pip install git+https://github.com/huggingface/peft.git@\\\n",
    "##  e7b75070c72a88f0f7926cc6872858a2c5f0090d\n",
    "##  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#\n",
    "###############################################\n",
    "\n",
    "name: t5-and-lora\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.10.14\n",
    "  - pip=24.1.2\n",
    "  - pip:\n",
    "      - pip==24.1.2\n",
    "      - accelerate==0.30.1\n",
    "      - bitsandbytes==0.43.1\n",
    "      - datasets==2.19.1\n",
    "      - evaluate==0.4.2\n",
    "      - huggingface-hub==0.23.2\n",
    "      - humanfriendly==10.0\n",
    "      - jupyter==1.0.0\n",
    "      - nltk==3.8.1\n",
    "      - psutil==6.0.0\n",
    "      - py-cpuinfo==9.0.0\n",
    "      - pylspci==0.4.3\n",
    "      - rouge-score==0.1.2\n",
    "      - torch==2.3.0\n",
    "      - transformers==4.41.1\n",
    "      - trl==0.8.6\n",
    "      - wmi==1.5.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3ea572-3189-4982-8e10-9f0d26c0428d",
   "metadata": {},
   "source": [
    "#### Possible conda then pip install - recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e43f62-171f-4b10-8f6f-53ef157caae3",
   "metadata": {},
   "source": [
    "If packages aren't installed - a situation that happens every time with CoLab and that will happen the first time on my CPU-with-Windows-in-the-corner-compy-with-three-screens - this is the suggested way to go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a725ebf-04d1-4fef-891f-7b92cef7fc4c",
   "metadata": {},
   "source": [
    "#### Local Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cac62d-66aa-4833-96a8-dc3306e8b7ea",
   "metadata": {},
   "source": [
    "<b>1-local)</b> From a local machine (First time only)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;<b>(a)</b> (First time only) Start from a shell. Create a conda environment; I do it from `Conda Prompt (miniconda3)`.\n",
    "     \n",
    "        conda create --name t5-and-lora python=3.10.14\n",
    "        conda activate t5-and-lora\n",
    "        \n",
    "        pip install --upgrade pip==24.1.2\n",
    "          # note that you should use the `--upgrade` whether upgrading or downgrading pip\n",
    "        \n",
    "        ## possibly needed\n",
    "        C:\\Users\\bballdave025\\.conda\\envs\\t5-and-lora\\python.exe -m pip install --upgrade pip==24.1.2\n",
    "        \n",
    "        pip install jupyter==1.0.0\n",
    "        \n",
    "        jupyter notebook SecondFullLoRA_w_Transformer.ipynb\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(The notebook, and the conda environment for that matter, might have different names.)\n",
    "     \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;<b>(b)</b> (First time only) Installations.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>(i)</b> Go to the `!pip install` parts ([Install TL;DR](#Install-TL;DR)), making sure that you set the `do_pip_installs` boolean to `True`.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>(ii)</b> Do the installs.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>(iii)</b> \\[Optional\\] Run the `!pip freeze` and copy/paste the results to an info spot for local machine.\n",
    "\n",
    "<b>2-local)</b> (First and subsequent times) Start from a shell. Get into the working directory of the Jupyter notebook. Activate the conda environment and launch the Jupyter notebook.\n",
    "\n",
    "     conda activate t5-plus-lora\n",
    "     jupyter notebook SecondFullLoRA_w_Transformer.ipynb\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(The notebook, and the conda environment for that matter, might have different names.)\n",
    "\n",
    "<b>3-local)</b> (Subsequent times) Do not re-run the `!pip install` commands unless something has gone wrong. Make sure that you set the `do_pip_installs` boolean to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c37c486-1404-4e7f-95e6-75edeb46b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install TL;DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55412c6-fd77-4f8a-a35a-092129e76ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  If the installs have been completed - either through conda\n",
    "##+ or through having previously run this notebook, this boolean\n",
    "##+ should have a `False` value\n",
    "\n",
    "do_pip_installs = False\n",
    "if do_pip_installs:\n",
    "    !powershell -c (Get-Date -UFormat \"%s_%Y%m%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_' > this_install_outfile.txt\n",
    "      # no 2>&1. I want to see errors (and only errors for now)\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c4f32-2f46-4e70-8f93-f291fd096971",
   "metadata": {},
   "source": [
    "Once you have things ready and a jupyter notebook running, you can do the `!pip install` commands that follow, depending on whether you are in CoLab or on a local machine, and whether or not it's the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b72176-5189-49c5-b77d-f28e3a74093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !C:\\Users\\bballdave025\\.conda\\envs\\rwkv-lora-dave\\python.exe -m pip install --upgrade pip==24.1.2 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ccde081-d3d4-4e38-858d-62de4a907112",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Ran into issues with imports; seems some got skipped (?)\n",
    "#\n",
    "#if do_pip_installs:\n",
    "#    !pip install accelerate bitsandbytes evaluate datasets huggingface-hub\n",
    "#    !pip install humanfriendly nltk py-cpuinfo pylspci rouge-score\n",
    "#    !pip install tensorflow-cpu torch transformers trl\n",
    "###endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514a98c2-a5e0-4320-ace1-2d3b31d6222e",
   "metadata": {},
   "source": [
    "Trying this next one on its own, since it might fail when not on Windows. `wmi` <b>Update:</b> This installs fine on CoLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94cefa7e-ed4a-4037-a4ef-bb3a56e55a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Putting it down the list\n",
    "# \n",
    "#if do_pip_installs:\n",
    "#    !pip install wmi\n",
    "###endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "557beaa2-77ff-444e-9e5c-d2fb3ac28752",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install accelerate==0.30.1 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb744b29-214f-445c-9baa-772ca1753e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install bitsandbytes==0.43.1 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "081e170f-f3b8-4328-8636-01aa66fcf4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install datasets==2.19.1 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "697aa28a-cfb2-427a-ac53-1fa0a9c11f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install evaluate==0.4.2 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7742314f-b8fd-4de9-927f-41252037b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install huggingface-hub==0.23.2 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a284e884-a975-4100-ac44-9e2a00e14f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install humanfriendly==10.0 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e9e7c6a-8c53-4a6f-a75f-156d95e4f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install nltk==3.8.1 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e4cfa32-cbca-4a8d-9294-ddfeabadbb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install py-cpuinfo==9.0.0 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b781dc9f-0e98-4712-bec9-0462f145f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install pylspci==0.4.3 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0164ba4-6b4d-4c35-8288-6198c0060a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install rouge-score==0.1.2 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7887cb94-4933-4967-94e3-9decb5bef8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install tensorflow==2.16.1 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8f56891-b4d8-4332-89ca-56d45a9bc768",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install torch==2.3.0 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e19d2e02-7568-4c8c-9b97-bee2b562e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install transformers==4.41.1 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52485dc3-b36c-4ac5-95bc-972849d3e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install trl==0.8.6 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "923e7bfe-bafe-48a9-bd3c-ff0a31f2b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install wmi==1.5.1 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8d771e-ec02-4ab3-9076-d1375ba994a9",
   "metadata": {},
   "source": [
    "And now, for the installs from GitHub repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a1d752d-cb63-42bb-9de2-ef036bc9d36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install git+https://github.com/huggingface/peft.git@e7b75070c72a88f0f7926cc6872858a2c5f0090d >> this_install_outfile.txt\n",
    "    # maybe get new commit hash @e7b75070c72a88f0f7926cc6872858a2c5f0090d\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6bda76-d0e4-441c-a1cf-94705cbfadb4",
   "metadata": {},
   "source": [
    "Output was\n",
    "\n",
    "```\n",
    "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git ^\n",
    "    'C:\\Users\\bballdave025\\AppData\\Local\\Temp\\pip-req-build-j8w_x47_'\n",
    "  Running command git rev-parse -q --verify 'sha^e7b75070c72a88f0f7926cc6872858a2c5f0090d'\n",
    "  Running command git fetch -q https://github.com/huggingface/peft.git e7b75070c72a88f0f7926cc6872858a2c5f0090d\n",
    "  Running command git checkout -q e7b75070c72a88f0f7926cc6872858a2c5f0090d\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86777773-5037-4547-bdc8-fbd11d1d7f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_pip_installs:\n",
    "    !pip install git+https://github.com/nexplorer-3e/qwqfetch.git@f72d222e2fff5ffea9f4e4b3a203e4c4d9e8cf00 >> this_install_outfile.txt\n",
    "    # make sure to get new commit hash @f72d222e2fff5ffea9f4e4b3a203e4c4d9e8cf00 >> this_install_outfile.txt\n",
    "##endof:  if do_pip_installs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc61b023-52e4-4e8b-a204-b1e7474c335a",
   "metadata": {},
   "source": [
    "Output was\n",
    "\n",
    "```\n",
    "  Running command git clone --filter=blob:none --quiet https://github.com/nexplorer-3e/qwqfetch.git ^\n",
    "    'C:\\Users\\Anast\\AppData\\Local\\Temp\\pip-req-build-5z5w4uco'\n",
    "  Running command git rev-parse -q --verify 'sha^f72d222e2fff5ffea9f4e4b3a203e4c4d9e8cf00'\n",
    "  Running command git fetch -q https://github.com/nexplorer-3e/qwqfetch.git f72d222e2fff5ffea9f4e4b3a203e4c4d9e8cf00\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fc1698c-0b90-4f80-b302-5f4faac4bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_see_install_outputs = False\n",
    "\n",
    "if do_see_install_outputs:\n",
    "    !type this_install_outfile.txt\n",
    "##endof:  if do_see_install_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38088590-038d-4e52-b98e-a9e141dd4823",
   "metadata": {},
   "source": [
    "## Specifics for Windows CPU Environment - minimize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81ada510-245c-4983-9e05-8400d0adba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't need this again\n",
    "#!powershell -c (Get-Date -UFormat \"%s_%Y%m%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317b0e72-f900-44c2-a00c-b3ee28723873",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`1721754699_20240723T171139-0600`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d2c8fc7-eea8-4087-ab53-0556e62be21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_see_current_requirements = False\n",
    "\n",
    "if do_see_current_requirements:\n",
    "    !powershell -c (Get-Date -UFormat \"%s_%Y%m%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'\n",
    "    !pip freeze\n",
    "    !pip freeze > requirements_loraflan_wincpu.txt\n",
    "##endof:  if do_see_current_requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d612ec6-9860-4b0b-b94b-d759b2cf412f",
   "metadata": {},
   "source": [
    "For Windows CPU, I got the following from `!pip freeze` (along with the prepended timestamp)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a487f7-ece0-4e73-8fd5-2647160cbbcb",
   "metadata": {},
   "source": [
    "```\n",
    "1721754699_20240723T171139-0600\n",
    "absl-py==2.1.0\n",
    "accelerate==0.30.1\n",
    "aiohttp==3.9.5\n",
    "aiosignal==1.3.1\n",
    "anyio==4.4.0\n",
    "argon2-cffi==23.1.0\n",
    "argon2-cffi-bindings==21.2.0\n",
    "arrow==1.3.0\n",
    "asttokens==2.4.1\n",
    "astunparse==1.6.3\n",
    "async-lru==2.0.4\n",
    "async-timeout==4.0.3\n",
    "attrs==23.2.0\n",
    "Babel==2.15.0\n",
    "beautifulsoup4==4.12.3\n",
    "bitsandbytes==0.43.1\n",
    "bleach==6.1.0\n",
    "cached-property==1.5.2\n",
    "certifi==2024.7.4\n",
    "cffi==1.16.0\n",
    "charset-normalizer==3.3.2\n",
    "click==8.1.7\n",
    "colorama==0.4.6\n",
    "comm==0.2.2\n",
    "datasets==2.19.1\n",
    "debugpy==1.8.2\n",
    "decorator==5.1.1\n",
    "defusedxml==0.7.1\n",
    "dill==0.3.8\n",
    "docstring_parser==0.16\n",
    "evaluate==0.4.2\n",
    "exceptiongroup==1.2.2\n",
    "executing==2.0.1\n",
    "fastjsonschema==2.20.0\n",
    "filelock==3.15.3\n",
    "flatbuffers==24.3.25\n",
    "fqdn==1.5.1\n",
    "frozenlist==1.4.1\n",
    "fsspec==2024.3.1\n",
    "gast==0.6.0\n",
    "google-pasta==0.2.0\n",
    "grpcio==1.65.1\n",
    "h11==0.14.0\n",
    "h5py==3.11.0\n",
    "httpcore==1.0.5\n",
    "httpx==0.27.0\n",
    "huggingface-hub==0.23.2\n",
    "humanfriendly==10.0\n",
    "idna==3.7\n",
    "intel-openmp==2021.4.0\n",
    "ipykernel==6.29.5\n",
    "ipython==8.26.0\n",
    "ipywidgets==8.1.3\n",
    "isoduration==20.11.0\n",
    "jedi==0.19.1\n",
    "Jinja2==3.1.4\n",
    "joblib==1.4.2\n",
    "json5==0.9.25\n",
    "jsonpointer==3.0.0\n",
    "jsonschema==4.23.0\n",
    "jsonschema-specifications==2023.12.1\n",
    "jupyter==1.0.0\n",
    "jupyter-console==6.6.3\n",
    "jupyter-events==0.10.0\n",
    "jupyter-lsp==2.2.5\n",
    "jupyter_client==8.6.2\n",
    "jupyter_core==5.7.2\n",
    "jupyter_server==2.14.2\n",
    "jupyter_server_terminals==0.5.3\n",
    "jupyterlab==4.2.4\n",
    "jupyterlab_pygments==0.3.0\n",
    "jupyterlab_server==2.27.3\n",
    "jupyterlab_widgets==3.0.11\n",
    "keras==3.4.1\n",
    "libclang==18.1.1\n",
    "Markdown==3.6\n",
    "markdown-it-py==3.0.0\n",
    "MarkupSafe==2.1.5\n",
    "matplotlib-inline==0.1.7\n",
    "mdurl==0.1.2\n",
    "mistune==3.0.2\n",
    "mkl==2021.4.0\n",
    "ml-dtypes==0.3.2\n",
    "mpmath==1.3.0\n",
    "multidict==6.0.5\n",
    "multiprocess==0.70.16\n",
    "namex==0.0.8\n",
    "nbclient==0.10.0\n",
    "nbconvert==7.16.4\n",
    "nbformat==5.10.4\n",
    "nest-asyncio==1.6.0\n",
    "networkx==3.3\n",
    "nltk==3.8.1\n",
    "notebook==7.2.1\n",
    "notebook_shim==0.2.4\n",
    "numpy==1.26.4\n",
    "opt-einsum==3.3.0\n",
    "optree==0.12.1\n",
    "overrides==7.7.0\n",
    "packaging==24.1\n",
    "pandas==2.2.2\n",
    "pandocfilters==1.5.1\n",
    "parso==0.8.4\n",
    "peft @ git+https://github.com/huggingface/peft.git@e7b75070c72a88f0f7926cc6872858a2c5f0090d\n",
    "platformdirs==4.2.2\n",
    "prometheus_client==0.20.0\n",
    "prompt_toolkit==3.0.47\n",
    "protobuf==4.25.3\n",
    "psutil==6.0.0\n",
    "pure_eval==0.2.3\n",
    "py-cpuinfo==9.0.0\n",
    "pyarrow==17.0.0\n",
    "pyarrow-hotfix==0.6\n",
    "pycparser==2.22\n",
    "Pygments==2.18.0\n",
    "pylspci==0.4.3\n",
    "pyreadline3==3.4.1\n",
    "python-dateutil==2.9.0.post0\n",
    "python-json-logger==2.0.7\n",
    "pytz==2024.1\n",
    "pywin32==306\n",
    "pywinpty==2.0.13\n",
    "PyYAML==6.0.1\n",
    "pyzmq==26.0.3\n",
    "qtconsole==5.5.2\n",
    "QtPy==2.4.1\n",
    "qwqfetch @ git+https://github.com/nexplorer-3e/qwqfetch.git@f72d222e2fff5ffea9f4e4b3a203e4c4d9e8cf00\n",
    "referencing==0.35.1\n",
    "regex==2024.5.15\n",
    "requests==2.32.3\n",
    "rfc3339-validator==0.1.4\n",
    "rfc3986-validator==0.1.1\n",
    "rich==13.7.1\n",
    "rouge_score==0.1.2\n",
    "rpds-py==0.19.0\n",
    "safetensors==0.4.3\n",
    "Send2Trash==1.8.3\n",
    "shtab==1.7.1\n",
    "six==1.16.0\n",
    "sniffio==1.3.1\n",
    "soupsieve==2.5\n",
    "stack-data==0.6.3\n",
    "sympy==1.12.1\n",
    "tbb==2021.13.0\n",
    "tensorboard==2.16.2\n",
    "tensorboard-data-server==0.7.2\n",
    "tensorflow==2.16.1\n",
    "tensorflow-intel==2.16.1\n",
    "tensorflow-io-gcs-filesystem==0.31.0\n",
    "termcolor==2.4.0\n",
    "terminado==0.18.1\n",
    "tinycss2==1.3.0\n",
    "tokenizers==0.19.1\n",
    "tomli==2.0.1\n",
    "torch==2.3.0\n",
    "tornado==6.4.1\n",
    "tqdm==4.66.4\n",
    "traitlets==5.14.3\n",
    "transformers==4.41.1\n",
    "trl==0.8.6\n",
    "types-python-dateutil==2.9.0.20240316\n",
    "typing_extensions==4.12.2\n",
    "tyro==0.8.5\n",
    "tzdata==2024.1\n",
    "uri-template==1.3.0\n",
    "urllib3==2.2.2\n",
    "wcwidth==0.2.13\n",
    "webcolors==24.6.0\n",
    "webencodings==0.5.1\n",
    "websocket-client==1.8.0\n",
    "Werkzeug==3.0.3\n",
    "widgetsnbextension==4.0.11\n",
    "WMI==1.5.1\n",
    "wrapt==1.16.0\n",
    "xxhash==3.4.1\n",
    "yarl==1.9.4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb51da5-6c05-4870-931c-7068e575ac99",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71faaa6c-fcbb-44d3-9740-8ed976b22d24",
   "metadata": {},
   "source": [
    "On a local machine (not on CoLab) you shouldn't need to know about the files in the current working directory, other than as information that might be useful in understanding where we're loading datasets or where the modules I've made live.\n",
    "\n",
    "Modules: `system_info_as_script.py`, `dwb_rouge_scores.py`, and `dwb_scoring_utils_rouge.py`.\n",
    "\n",
    "Dataset files: `samsum-train.csv`, `samsum-validation.csv`, and `samsum-test.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af7c2afe-9b5f-4ee6-9db6-9f8d2cf6b1d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found. Error loading \"C:\\Users\\Anast\\.conda\\envs\\t5-and-lora\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m randrange\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, \\\n\u001b[0;32m      6\u001b[0m                          AutoModelForSeq2SeqLM, \\\n\u001b[0;32m      7\u001b[0m                          TrainingArguments, \\\n\u001b[0;32m      8\u001b[0m                          pipeline\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n",
      "File \u001b[1;32m~\\.conda\\envs\\t5-and-lora\\lib\\site-packages\\torch\\__init__.py:141\u001b[0m\n\u001b[0;32m    139\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    140\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 141\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    143\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\Anast\\.conda\\envs\\t5-and-lora\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "from random import randrange\n",
    "import torch\n",
    "from transformers import AutoTokenizer, \\\n",
    "                         AutoModelForSeq2SeqLM, \\\n",
    "                         TrainingArguments, \\\n",
    "                         pipeline\n",
    "from transformers.utils import logging\n",
    "from peft import LoraConfig, \\\n",
    "                 prepare_model_for_kbit_training, \\\n",
    "                 get_peft_model, \\\n",
    "                 AutoPeftModelForSeq2SeqLM, \\\n",
    "                 AutoPeftModelForCausalLM, \\\n",
    "                 PeftConfig, \\\n",
    "                 PeftModel\n",
    "from trl import SFTTrainer\n",
    "from huggingface_hub import login, notebook_login\n",
    "\n",
    "import nltk\n",
    "import rouge_score\n",
    "from rouge_score import rouge_scorer, scoring\n",
    "\n",
    "import pickle\n",
    "import pprint\n",
    "import re\n",
    "import timeit\n",
    "from humanfriendly import format_timespan\n",
    "import os\n",
    "\n",
    "## my module(s), now just in the working directory as .PY files\n",
    "import system_info_as_script\n",
    "import dwb_rouge_scores\n",
    "from dwb_scoring_utils_rouge import compute_google_rouge_score, \\\n",
    "                                    format_rouge_score_rough, \\\n",
    "                                    print_rouge_scores\n",
    "from dwb_text_utils_data_rep import wc, \\\n",
    "                                    head, \\\n",
    "                                    first_n_chars_in_file, \\\n",
    "                                    csv2json_bare_builtins, \\\n",
    "                                    csv2json_better_builtins_indent, \\\n",
    "                                    csv2json_overkill_builtins_robust, \\\n",
    "                                    csv2json_pandas_basic\n",
    "\n",
    "## to hide all the warnings\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6ab700-958a-4d86-a3e9-b466e978a032",
   "metadata": {},
   "source": [
    "If there's an error such as\n",
    "\n",
    "`OSError: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\bballdave025\\.conda\\envs\\t5-and-lora\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.`\n",
    " \n",
    "try adding\n",
    "\n",
    "`C:\\Users\\bballdave025\\AppData\\Roaming\\Python\\Library\\bin`\n",
    "\n",
    "to the `Path`. \n",
    "\n",
    "(You'll have to close the Jupyter Notebook, exit and restart the terminal/conda prompt, load the conda environment, and try the imports again.)\n",
    "\n",
    "This path contains a bunch of `mkl` stuff, which is what's missing.\n",
    "\n",
    "By the way, `shm.dll` does exist at the path listed above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b969a2b-40d6-4c63-998a-170415a8fb57",
   "metadata": {},
   "source": [
    "### To get rid of all warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd7562c-2803-4292-8519-2403790d03b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_ignore_all_warnings = False\n",
    "\n",
    "if do_ignore_all_warnings:\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "##endof:  if do_ignore_all_warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab12da-9cbc-409c-bc1c-b13ce0c9ccd3",
   "metadata": {},
   "source": [
    "## Saving stuff to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d9d50d-e52c-4559-b9a3-e47ed44ec9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_filename = \"lora_flan_t5_cpu_objects.pkl\"\n",
    "objects_to_pickle = []\n",
    "objects_to_pickle_var_names = []\n",
    "\n",
    "#incremental\n",
    "objects_to_pickle_01 = []\n",
    "objects_to_pickle_var_names_01 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bfe2f4-b1b4-4158-b3c6-048c487514d2",
   "metadata": {},
   "source": [
    "## Load the training, validation, and test dataset along with the LLM and its tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b3851-3d58-454f-9c8a-0013054eb448",
   "metadata": {},
   "source": [
    "The LLM will be fine-tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b8d64-6812-4812-b489-bd0d98d12ae1",
   "metadata": {},
   "source": [
    "### Converting from CSV to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b42e10c-ddae-4267-aac1-3a44de131b97",
   "metadata": {},
   "source": [
    "I won't put in all the docs for my methods. <strike>Actually, maybe I will, since I don't remember how I set them all up.</strike>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c27d5f-e443-49b0-ad61-d3f79e2dc8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_fname = \"samsum-train.csv\"\n",
    "validate_csv_fname = \"samsum-validation.csv\"\n",
    "test_csv_fname = \"samsum-test.csv\"\n",
    "\n",
    "## to be written\n",
    "train_json_fname = \"samsum-train.json\"\n",
    "validate_json_fname = \"samsum-validation.json\"\n",
    "test_json_fname = \"samsum-test.json\"\n",
    "\n",
    "csv2json_better_builtins_indent(train_csv_fname, train_json_fname)\n",
    "csv2json_better_builtins_indent(validate_csv_fname, validate_json_fname)\n",
    "csv2json_better_builtins_indent(test_csv_fname, test_csv_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76db1ff-240e-48d5-a187-7171b9de467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir | findstr \"json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8694116c-3b09-4014-bca1-4bb8fa0582c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"wc (like bash) (word count) for the test files.\")\n",
    "print(\"CSV\")\n",
    "wc(train_csv_fname)\n",
    "print(\"JSON\")\n",
    "wc(train_json_fname)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"head (like bash) (first 5 lines) for the test files.\")\n",
    "print(\"CSV\")\n",
    "head(5, train_csv_fname)\n",
    "print(\"JSON\")\n",
    "head(5, train_json_fname)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"First 150 characters of the test files.\")\n",
    "print(\"CSV\")\n",
    "first_n_chars_in_file(150, train_csv_fname)\n",
    "print(\"JSON\")\n",
    "first_n_chars_in_file(150, train_json_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6043d426-bcee-4539-a9ea-4b7c4c3dccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {'train':'samsum-train.json', \n",
    "              'evaluation':'samsum-validation.json',\n",
    "              'test':'samsum-test.json'}\n",
    "dataset = load_dataset('json', data_files=data_files)\n",
    "\n",
    "model_name = \"google/flan-t5-small\"\n",
    "\n",
    "model_load_tic = timeit.default_timer()\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model_load_toc = timeit.default_timer()\n",
    "\n",
    "model_load_duration = model_load_toc - model_load_tic\n",
    "\n",
    "print(f\"Loading the original model, {model_name}\")\n",
    "print(f\"took {model_load_toc - model_load_tic:0.4f} seconds.\")\n",
    "\n",
    "model_load_time_str = format_timespan(model_load_duration)\n",
    "\n",
    "print(f\"which equates to {model_load_time_str}\")\n",
    "\n",
    "#  Next line makes training faster but a little less accurate\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer_tic = timeit.default_timer()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, \n",
    "                                          trust_remote_code=True)\n",
    "tokenizer_toc = timeit.default_timer()\n",
    "\n",
    "tokenizer_duration = tokenizer_toc - tokenizer_tic\n",
    "\n",
    "print()\n",
    "print(\"Getting the original tokenizer\")\n",
    "print(f\"took {tokenizer_toc - tokenizer_tic:0.4f} seconds.\")\n",
    "\n",
    "tokenizer_time_str = format_timespan(tokenizer_duration)\n",
    "\n",
    "print(f\"which equates to {tokenizer_time_str}\")\n",
    "\n",
    "#  padding instructions for the tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d12b71-cfa1-475b-89dc-1c82dc589409",
   "metadata": {},
   "source": [
    "### Saving the model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4d803-a08c-4a4f-8b67-20ff522bcc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_to_pickle.append(model_name)\n",
    "objects_to_pickle_var_names.append('model_name')\n",
    "\n",
    "#incremental\n",
    "objects_to_pickle_01.append(model_name)\n",
    "objects_to_pickle_var_names_01.append('model_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc6b24-d617-48a1-8236-c3be16402c4a",
   "metadata": {},
   "source": [
    "### Trying some things I've been learning (architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a107cbdc-5a73-4371-8afe-faa2dc623c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aaf9b8-19fe-4255-81bb-47dfa40cfcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arch_str = str(model)\n",
    "\n",
    "with open(\"google_-flan-t5-small.model-architecture.txt\", 'w', encoding='utf-8') as fh:\n",
    "    fh.write(model_arch_str)\n",
    "##endof:  with open ... fh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6685b823-98dc-4b44-931a-6ead83f9b138",
   "metadata": {},
   "source": [
    "#### Some other saves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c96c5-120d-40ca-8452-8ca4a9225030",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_to_pickle.append(model_arch_str)\n",
    "objects_to_pickle_var_names.append('model_arch_str')\n",
    "\n",
    "#incremental\n",
    "objects_to_pickle_01.append(model_arch_str)\n",
    "objects_to_pickle_var_names_01.append('model_arch_str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cdd3ac-f714-41ed-a1fb-c27395b9251d",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb36fc-783f-4f19-b213-69cc3dbf05af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_instruction_format(sample):\n",
    "    return f\"\"\" Instruction:\n",
    "      Use the Task below and the Input given to write the Response:\n",
    "\n",
    "      ### Task:\n",
    "      Summarize the Input\n",
    "\n",
    "      ### Input:\n",
    "      {sample['dialogue']}\n",
    "\n",
    "      ### Response:\n",
    "      {sample['summary']}\n",
    "      \"\"\"\n",
    "##endof:  prompt_instruction_format(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3622673e-df80-43da-9d5c-efd6085d301d",
   "metadata": {},
   "source": [
    "## Trainer - the LoRA Setup Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f765206-7013-41b9-b833-b6b05fa5f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't need this anymore\n",
    "!powershell -c (Get-Date -UFormat \"%s_%Y%m%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68615f69-ca62-4ac2-afeb-935b12144b15",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1777bfa5-26ae-4e10-af7f-38f9f919db88",
   "metadata": {},
   "source": [
    "#### Okay, here are the args and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac040cf-2eb5-4eb5-91c7-2e47c54b990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  some arguments to pass to the trainer\n",
    "training_args = TrainingArguments(\n",
    "                    output_dir='output',\n",
    "                    num_train_epochs=1,\n",
    "                    per_device_train_batch_size=4,\n",
    "                    learning_rate=2e-4,\n",
    "                    do_eval=True,\n",
    "                    per_device_eval_batch_size=4,\n",
    "                    eval_strategy='steps',\n",
    "                    eval_steps=250, # will do 250, then 50\n",
    "                    hub_model_id=\" \",\n",
    "                    save_strategy='steps',\n",
    "                    save_steps=250,\n",
    "                    overwrite_output_dir=True,\n",
    "                    #log_level='info', # uncomment to see details\n",
    "                    logging_dir='logging',\n",
    "                    logging_strategy='steps',\n",
    "                    logging_first_step=True,\n",
    "                    logging_steps=250,\n",
    ")\n",
    "\n",
    "#  the fine-tuning (peft for LoRA) stuff\n",
    "peft_config = LoraConfig(lora_alpha=16,\n",
    "                         lora_dropout=0.1,\n",
    "                         r=16,\n",
    "                         bias='none',\n",
    "                         task_type='CAUSAL_LM',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62112e42-f16a-43d2-a7d4-1a086039c966",
   "metadata": {},
   "source": [
    "### Details on `TrainingArguments`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aabf457-4107-43fa-acc2-571f91dd52d8",
   "metadata": {},
   "source": [
    "Documentation is at:\n",
    "\n",
    "https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments\n",
    "\n",
    "archived at\n",
    "\n",
    "https://web.archive.org/web/20240608164657/https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments\n",
    "\n",
    "The actual file (from which the docs come) is at the following path on my computer\n",
    "\n",
    "`C:\\Users\\bballdave025\\.conda\\envs\\rwkv-lora-pat\\Lib\\site-packages\\transformers\\training_args.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e178f3f-9dd6-409e-9a4d-c1c85611a8b9",
   "metadata": {},
   "source": [
    "### We're going to start timing stuff, so here's some system info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff95ed1-4959-4181-b516-cd2e560af9dc",
   "metadata": {},
   "source": [
    "`system_info_as_script.py` is a script I wrote with the help\n",
    "of a variety of StackOverflow and documentation sources.\n",
    "It should be in the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14193c4-9040-47ea-9504-37ccb408de9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't need this again\n",
    "!powershell -c (Get-Date -UFormat \"%s_%Y%m%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c21dc0c-1b97-45d5-b436-ff516116c7c5",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e51b0-8f09-4693-b991-e853ca3cfccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "system_info_as_script.run(do_network_info=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2c07f3-1066-48ac-a243-8ec5af8f528e",
   "metadata": {},
   "source": [
    "#### Find specific dialog - minimize\n",
    "\n",
    "I found a nice, short, interesting conversation while doing the random summaries, so I went and found its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46472dc-5f9d-44a4-a959-4f2053d9de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = timeit.default_timer()\n",
    "\n",
    "str_to_find = \"Damien: Omg..I'm glad Sunday is only once a week\"\n",
    "\n",
    "for sample_num in range(len(dataset['test'])):\n",
    "    this_sample = dataset['test'][sample_num]\n",
    "    this_dialogue = this_sample['dialogue']\n",
    "    if str_to_find in this_dialogue:\n",
    "        print(f\"sample_num: {sample_num}\")\n",
    "        print(f\"this_dialogue: \\n{this_dialogue}\")\n",
    "        print()\n",
    "        print(\"this_sample:\")\n",
    "        print(str(this_sample))\n",
    "        print()\n",
    "    ##endof:  if str_to_find in this_dialogue\n",
    "##endof:  for sample_number in range(len(dataset))\n",
    "\n",
    "toc = timeit.default_timer()\n",
    "\n",
    "print(\"Finding the sample in the test dataset (well,\")\n",
    "print(\"actually looking at every sample in the test\")\n",
    "print(\"dataset, regardless of whether we had found\")\n",
    "print(\"something.\")\n",
    "print(f\"took {toc - tic:0.4f} seconds.\")\n",
    "\n",
    "my_duration = toc - tic\n",
    "\n",
    "elapsed_time_str = format_timespan(my_duration)\n",
    "\n",
    "print(f\"which equates to {elapsed_time_str}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"Total size of test dataset: {sample_num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf6c61-92bc-4453-8cc5-ec606556ca69",
   "metadata": {},
   "source": [
    "The interesting conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff68a6-4038-4601-9b10-55138fde82e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_index = 224\n",
    "my_complete_entry = dataset['test'][my_index]\n",
    "my_cool_str = dataset['test'][my_index]['dialogue']\n",
    "print(my_cool_str)\n",
    "objects_to_pickle.append(my_cool_str)\n",
    "objects_to_pickle_var_names.append('my_cool_str')\n",
    "my_cool_list = [f\"my_index: {my_index}\", my_cool_str, my_complete_entry]\n",
    "pprint.pp(my_cool_list)\n",
    "objects_to_pickle.append(my_cool_list)\n",
    "objects_to_pickle_var_names.append('my_cool_list')\n",
    "\n",
    "#incremental\n",
    "objects_to_pickle_01.append(my_cool_str)\n",
    "objects_to_pickle_var_names_01.append('my_cool_str')\n",
    "objects_to_pickle_01.append(my_cool_list)\n",
    "objects_to_pickle_var_names_01.append('my_cool_list')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7216a22-a59a-401e-a52e-75a59ee57b97",
   "metadata": {},
   "source": [
    "### Let's get the sizes of all parts of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e975b16-9e5d-4b3f-b412-62267dad18ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_train = len(dataset['train'])\n",
    "size_of_eval = len(dataset['evaluation'])\n",
    "size_of_test = len(dataset['test'])\n",
    "\n",
    "print(f\"size_of_train : {size_of_train}\")\n",
    "print(f\"size_of_eval  : {size_of_eval}\")\n",
    "print(f\"size_of_test  : {size_of_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5cd858-f6e7-4dba-b689-75e3d950f26d",
   "metadata": {},
   "source": [
    "### Try for a baseline (for out-of-the-box, pretrained model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d4b1ed-9b22-43df-8c0c-53f6afa88a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't need this again\n",
    "!powershell -c (Get-Date -UFormat \"%s_%Y%m%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e457a41-5f41-44c7-8b1f-e50a5b007ee7",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba0b4db-cd1c-466c-91be-cc0e2a8a14c1",
   "metadata": {},
   "source": [
    "#### Just one summarization to begin with, randomly picked\n",
    "\n",
    "##### Well, not so randomly, anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c8f7d8-f4f0-4e2a-b457-ee6db19155a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline('summarization', \n",
    "                      model=model, \n",
    "                      tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29baca78-f216-4cce-9150-df2d38ee7307",
   "metadata": {},
   "source": [
    "Just one summarization to begin with, randomly picked ... but\n",
    "now with th possibility of a known seed, to allow visual \n",
    "comparison with after-training results.\n",
    "\n",
    "<strike>I'M NOT GOING TO USE THIS REPEATED SEED, I'm just going to\n",
    "use the datum at the first index to compare.</strike>\n",
    "\n",
    "For sharing with Pat, I'm making it repeatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68250f44-daf6-436e-a7d2-dcb7a8d97ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_seed_for_repeatable = True\n",
    "\n",
    "if do_seed_for_repeatable:\n",
    "    rand_seed_for_randrange = 137\n",
    "    random.seed(rand_seed_for_randrange)\n",
    "##endof:  if do_seed_for_repeatable\n",
    "\n",
    "sample = dataset['test'][randrange(len(dataset[\"test\"]))]\n",
    "print(f\"dialogue: \\n{sample['dialogue']}\\n---------------\")\n",
    "\n",
    "res = summarizer(sample[\"dialogue\"])\n",
    "\n",
    "print(f\"flan-t5-small summary:\\n{res[0]['summary_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21170b7-0685-4e39-b9d6-2eaf5624d476",
   "metadata": {},
   "source": [
    "#### Now, a couple summarizations with comparisons to ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a760e7-6270-4e65-93f0-1af0c3dd559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_list = []\n",
    "ref_test_list = []\n",
    "\n",
    "sample_num = 0\n",
    "\n",
    "this_sample = dataset['test'][sample_num]\n",
    "\n",
    "print(f\"dialogue: \\n{this_sample['dialogue']}\\n---------------\")\n",
    "\n",
    "ground_summary = this_sample['summary']\n",
    "res = summarizer(this_sample['dialogue'])\n",
    "res_summary = res[0]['summary_text']\n",
    "\n",
    "print(f\"human-genratd summary:\\n{ground_summary}\")\n",
    "print(f\"flan-t5-small summary:\\n{res_summary}\")\n",
    "\n",
    "ref_test_list.append(ground_summary)\n",
    "pred_test_list.append(res_summary)\n",
    "\n",
    "#  Yes, I have just one datum, but I'm setting things up to\n",
    "#+ work well with a later loop, i.e. with lists\n",
    "results_test_0 = compute_google_rouge_score(\n",
    "                    predictions=pred_test_list,\n",
    "                    references=ref_test_list,\n",
    "                    use_aggregator=False\n",
    ")\n",
    "\n",
    "print(\"Output from 'list(results_test_0.keys())'\")\n",
    "print(list(results_test_0.keys()))\n",
    "# ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ab55d2-33b6-4c6f-802f-2ab97e0f8b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rouge_scores(results_test_0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84099d2-41e4-4266-a5e9-b7b7cac59504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  I don't want to aggregate, yet.\n",
    "pred_test_list = []\n",
    "ref_test_list = []\n",
    "\n",
    "sample_num = 224\n",
    "\n",
    "this_sample = dataset['test'][sample_num]\n",
    "\n",
    "print(f\"dialogue: \\n{this_sample['dialogue']}\\n---------------\")\n",
    "\n",
    "ground_summary = this_sample['summary']\n",
    "res = summarizer(this_sample['dialogue'])\n",
    "res_summary = res[0]['summary_text']\n",
    "\n",
    "print(f\"human-genratd summary:\\n{ground_summary}\")\n",
    "print(f\"flan-t5-small summary:\\n{res_summary}\")\n",
    "\n",
    "ref_test_list.append(ground_summary)\n",
    "pred_test_list.append(res_summary)\n",
    "\n",
    "results_test_224 = compute_google_rouge_score(\n",
    "                      predictions=pred_test_list,\n",
    "                      references=ref_test_list,\n",
    "                      use_aggregator=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf7d444-6d03-400c-b7ac-551d6aa4f6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rouge_scores(results_test_224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f099cc0c-bce3-49e5-8ca8-afd212adbc70",
   "metadata": {},
   "source": [
    "#### Verbosity stuff - get rid of the nice advice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea7a763-7427-4054-ab79-ee8d0931f25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't need this again\n",
    "!powershell -c (Get-Date -UFormat \"%s_%Y%m%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cb761d-d836-49a4-b585-29aae74f0c86",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb49d3a5-b58e-468a-836a-84a3908fd27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_verbosity_is_critical = \\\n",
    "  logging.get_verbosity() == logging.CRITICAL # alias FATAL, 50\n",
    "log_verbosity_is_error = \\\n",
    "  logging.get_verbosity() == logging.ERROR # 40\n",
    "log_verbosity_is_warn = \\\n",
    "  logging.get_verbosity() == logging.WARNING # alias WARN, 30\n",
    "log_verbosity_is_info = \\\n",
    "  logging.get_verbosity() == logging.INFO # 20\n",
    "log_verbosity_is_debug = \\\n",
    "  logging.get_verbosity() == logging.DEBUG # 10\n",
    "\n",
    "print( \"The statement, 'logging verbosity is CRITICAL' \" + \\\n",
    "      f\"is {log_verbosity_is_critical}\")\n",
    "print( \"The statement, 'logging verbosity is    ERROR' \" + \\\n",
    "      f\"is {log_verbosity_is_error}\")\n",
    "print( \"The statement, 'logging verbosity is  WARNING' \" + \\\n",
    "      f\"is {log_verbosity_is_warn}\")\n",
    "print( \"The statement, 'logging verbosity is     INFO' \" + \\\n",
    "      f\"is {log_verbosity_is_info}\")\n",
    "print( \"The statement, 'logging verbosity is    DEBUG' \" + \\\n",
    "      f\"is {log_verbosity_is_debug}\")\n",
    "\n",
    "print()\n",
    "\n",
    "init_log_verbosity = logging.get_verbosity()\n",
    "print(f\"The value of logging.get_verbosity() is: {init_log_verbosity}\")\n",
    "\n",
    "print()\n",
    "\n",
    "init_t_n_a_w = os.environ.get('TRANSFORMERS_NO_ADVISORY_WARNINGS')\n",
    "print(f\"TRANSFORMERS_NO_ADIVSORY_WARNINGS: {init_t_n_a_w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a66b11-e35e-4663-9bcc-602bd3cd060d",
   "metadata": {},
   "source": [
    "### Actual Baseline on Complete Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c671b535-247a-4510-9a09-d8db4fbeab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't need this again\n",
    "!powershell -c (Get-Date -UFormat \"%s_%Y%m%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5dca6b-d4ca-440e-bdd2-71869263c6d7",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08031760-1551-41f3-8a1e-1a4b8fef5513",
   "metadata": {},
   "source": [
    "<b>!!! NOTE</b> You'd better <b>make \n",
    "dang sure you want the lots of output</b> \n",
    "before you set this next boolean to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af21e6ae-43c6-4ea5-97e2-019d11e31abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_have_lotta_output_from_all_dialogs_summaries_1 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3db0ad-b6df-4124-aad7-74be50b62b9a",
   "metadata": {},
   "source": [
    "# Are you sure about the value of that last boolean? 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f4ea4-b239-4c74-a533-0371b28e140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"That last boolean has the value:\")\n",
    "print(f\"{do_have_lotta_output_from_all_dialogs_summaries_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454d771a-6fa6-47f3-9743-e3b2096382ab",
   "metadata": {},
   "source": [
    "There could be up to megabytes worth of text output if you've changed it to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c550c2-eee7-4393-9f92-1a25f4fcc2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Haven't tried this environment variable, \n",
    "##+ because the logging seemed easier,\n",
    "##+ and the logging worked\n",
    "#os.environ(\"TRANSFORMERS_NO_ADVISORY_WARNINGS\") = 1\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "baseline_sample_dialog_list = []\n",
    "baseline_prediction_list = []\n",
    "baseline_reference_list = []\n",
    "\n",
    "baseline_tic = timeit.default_timer()\n",
    "\n",
    "for sample_num in range(len(dataset['test'])):\n",
    "    this_sample = dataset['test'][sample_num]\n",
    "    \n",
    "    if do_have_lotta_output_from_all_dialogs_summaries_1:\n",
    "        print(f\"dialogue: \\n{this_sample['dialogue']}\\n---------------\")\n",
    "    ##endof:  if do_have_lotta_output_from_all_dialogs_summaries_1\n",
    "    \n",
    "    ground_summary = this_sample['summary']\n",
    "    res = summarizer(this_sample['dialogue'])\n",
    "    res_summary = res[0]['summary_text']\n",
    "    \n",
    "    if do_have_lotta_output_from_all_dialogs_summaries_1:\n",
    "        print(f\"human-genratd summary:\\n{ground_summary}\")\n",
    "        print(f\"flan-t5-small summary:\\n{res_summary}\")\n",
    "    ##endof:  if do_have_lotta_output_from_all_dialogs_summaries_1\n",
    "    \n",
    "    baseline_sample_dialog_list.append(this_sample['dialogue'])\n",
    "    baseline_reference_list.append(ground_summary)\n",
    "    baseline_prediction_list.append(res_summary)\n",
    "##endof:  for sample_num in range(len(dataset['test']))\n",
    "\n",
    "baseline_toc = timeit.default_timer()\n",
    "\n",
    "baseline_duration = baseline_toc - baseline_tic\n",
    "\n",
    "print( \"Getting things ready for scoring (doing the baseline)\")\n",
    "print(f\"took {baseline_toc - baseline_tic:0.4f} seconds.\")\n",
    "\n",
    "baseline_time_str = format_timespan(baseline_duration)\n",
    "\n",
    "print(f\"which equates to {baseline_time_str}\")\n",
    "\n",
    "rouge = load_metric('rouge', trust_remote_code=True)\n",
    "\n",
    "baseline_results = compute_google_rouge_score(\n",
    "                      predictions=baseline_prediction_list,\n",
    "                      references=baseline_reference_list,\n",
    "                      use_aggregator=True\n",
    ")\n",
    "\n",
    "# >>> print(list(baseline_results.keys()))\n",
    "# ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
    "\n",
    "objects_to_pickle.append(baseline_sample_dialog_list)\n",
    "objects_to_pickle_var_names.append('baseline_sample_dialog_list')\n",
    "objects_to_pickle.append(baseline_prediction_list)\n",
    "objects_to_pickle_var_names.append('baseline_prediction_list')\n",
    "objects_to_pickle.append(baseline_reference_list)\n",
    "objects_to_pickle_var_names.append('baseline_reference_list')\n",
    "objects_to_pickle.append(baseline_results)\n",
    "objects_to_pickle_var_names.append('baseline_results')\n",
    "\n",
    "#incremental\n",
    "objects_to_pickle_01.append(baseline_sample_dialog_list)\n",
    "objects_to_pickle_var_names_01.append('baseline_sample_dialog_list')\n",
    "objects_to_pickle_01.append(baseline_prediction_list)\n",
    "objects_to_pickle_var_names_01.append('baseline_prediction_list')\n",
    "objects_to_pickle_01.append(baseline_reference_list)\n",
    "objects_to_pickle_var_names_01.append('baseline_reference_list')\n",
    "objects_to_pickle_01.append(baseline_results)\n",
    "objects_to_pickle_var_names_01.append('baseline_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377fedc3-f857-4ba4-8729-07666336bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Haven't tried this environment variable, \n",
    "##+ because the logging seemed easier,\n",
    "##+ and the logging worked\n",
    "# os.environ(\"TRANSFORMERS_NO_ADVISORY_WARNINGS\") = init_t_n_a_w\n",
    "\n",
    "logging.set_verbosity(init_log_verbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4949e0-de52-485c-bbc2-559dd0db4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rouge_scores(baseline_results, \"BASELINE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f343f-e6d1-4634-8538-5986f9795b35",
   "metadata": {},
   "source": [
    "## A Saving Checkpoint - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91496082-dc2d-4afc-85b0-1202e7ab334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#incremental\n",
    "pickle_filename_before_training = \"lora_flan_t5_cpu_objects_-_01_before_training.pkl\"\n",
    "pickle_filename_01 = pickle_filename_before_training\n",
    "\n",
    "objects_to_pickle_var_names_01.append('objects_to_pickle_var_names_01')\n",
    "objects_to_pickle_01.append(objects_to_pickle_var_names_01)\n",
    "\n",
    "with open(pickle_filename_01, 'wb') as pfh:\n",
    "    pickle.dump(objects_to_pickle_01 , pfh)\n",
    "##endof:  with open ... as pfh # (pickle file handle)\n",
    "\n",
    "pickle_filename_02 = \"lora_flan_t5_cpu_objects_02.pkl\" # will likely change\n",
    "objects_to_pickle_02 = []\n",
    "objects_to_pickle_var_names_02 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df187315-53a9-4f66-a9f3-17db67512ddd",
   "metadata": {},
   "source": [
    "### Trainer - the Actual Trainer Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc41e49-b3b8-4ea0-a3e0-aa40e4860be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't need this again\n",
    "!powershell -c (Get-Date -UFormat \"%s_%Y-%m-%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5503fa3b-09b3-4b6e-b18c-3fb9791e715f",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4feb5c-bb3c-444d-8814-6efa2317ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer( model=model,\n",
    "                      train_dataset=dataset['train'],\n",
    "                      eval_dataset=dataset['evaluation'],\n",
    "                      peft_config=peft_config,\n",
    "                      tokenizer=tokenizer,\n",
    "                      packing=True,\n",
    "                      formatting_func=prompt_instruction_format,\n",
    "                      args=training_args,\n",
    "                      max_seq_length=750\n",
    ")\n",
    "##  Warnings are below output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d556f5-92e7-4bdc-bbd0-73d643050446",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "## Let's Train This LoRA Thing and See How It Does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a82f8-7f45-454c-b301-a591298171c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't need this again\n",
    "!powershell -c (Get-Date -UFormat \"%s_%Y-%m-%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd1014-d324-4293-930d-0ead8fdba381",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c15de9-adb4-433d-8a01-e633571bb076",
   "metadata": {},
   "source": [
    "### The long-time-taking training code is just below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4971f967-9d95-4606-9cc7-748834836b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = timeit.default_timer()\n",
    "trainer.train()\n",
    "toc = timeit.default_timer()\n",
    "print(f\"tic: {tic}\")\n",
    "print(f\"toc: {toc}\")\n",
    "training_duration = toc - tic\n",
    "print(f\"Training took {toc - tic:0.4f} seconds.\")\n",
    "training_time_str = format_timespan(training_duration)\n",
    "print(f\"which equates to {training_time_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76af041-ec4b-46d4-885d-783a50d33bc8",
   "metadata": {},
   "source": [
    "#### The training stats - CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aeb097-b873-4505-a909-fa044a42d1b3",
   "metadata": {},
   "source": [
    "(well, mostly just loss on training and validation sets) were\n",
    "\n",
    "##### When I checkpointed every 50 steps\n",
    "\n",
    "the values were\n",
    "\n",
    "```\n",
    "    Step  | Training Loss | Validation Loss\n",
    "  --------+---------------+------------------\n",
    "    50    |  1.830600     |  0.372227\n",
    "    100   |  0.448100     |  0.126734\n",
    "    150   |  0.251900     |  0.089366\n",
    "    200   |  0.202500     |  0.070181\n",
    "    250   |  0.173600     |  0.059308\n",
    "!!  ^^^      ^^^^^^^^        ^^^^^^^^\n",
    "    300   |       |  \n",
    "    350   |       |  \n",
    "    400   |       |  \n",
    "    450   |       |  \n",
    "    500   |       |  \n",
    "!!  ^^^      ^^^^^^^^        ^^^^^^^^\n",
    "    550   |       |  \n",
    "    600   |       |  \n",
    "    650   |       |  \n",
    "    700   |       |  \n",
    "    750   |       |  \n",
    "!!  ^^^      ^^^^^^^^        ^^^^^^^^\n",
    "    800   |       |  \n",
    "    850   |       |  \n",
    "    900   |       |  \n",
    "    950   |       |  \n",
    "    1000  |       |  \n",
    "!!  ^^^^     ^^^^^^^^        ^^^^^^^^\n",
    "```\n",
    "\n",
    "##### When I checkpointed every 250 steps \n",
    "\n",
    "the values were\n",
    "\n",
    "\n",
    "```\n",
    "                                               | Compare | 50-step  | 50-step\n",
    "    Step  | Training Loss | Validation Loss    | 50-step | T.L.     | V.L.\n",
    "  --------+---------------+------------------==+==-------+----------+----------\n",
    "    250   |               |                    |         |          |           \n",
    "    500   |               |                    |         |          |\n",
    "    750   |               |                    |         |          |\n",
    "   1000   |               |                    |         |          |\n",
    "```\n",
    "\n",
    "<b>N.B.</b> I don't know why it always stops at 1000 - I could look in the docs for a parameter, but I think we get the idea we want.\n",
    "Oh, I think that one step has 4 samples from the dataset, which would make things match up. Still, with the epoch run, I had 1536 steps.\n",
    "\n",
    "\n",
    "##### When I only checkpointed for the epoch\n",
    "\n",
    "the values were\n",
    "\n",
    "```\n",
    "  Training Loss | Epoch | Step | Validation Loss\n",
    " ---------------+-------+------+-----------------\n",
    "      0.0685    |  1.0  | 1536 |     0.0226\n",
    "```\n",
    "\n",
    "(I only have this for the CPU.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248f85a-14a5-4bf1-b84d-3bd88650381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_to_pickle.append(tokenizer)\n",
    "objects_to_pickle_var_names.append('tokenizer')\n",
    "objects_to_pickle.append(trainer)\n",
    "objects_to_pickle_var_names.append('trainer')\n",
    "\n",
    "#incremental\n",
    "objects_to_pickle_02.append(tokenizer)\n",
    "objects_to_pickle_var_names_02.append('tokenizer')\n",
    "objects_to_pickle_02.append(trainer)\n",
    "objects_to_pickle_var_names_02.append('trainer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c571124-8961-49e2-8e82-2624685136bb",
   "metadata": {},
   "source": [
    "## A Saving Checkpoint - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e92a5f-1c24-4157-a702-74919a9f219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#incremental\n",
    "pickle_filename_after_training = \"lora_flan_t5_cpu_objects_-_02_after_training.pkl\"\n",
    "pickle_filename_02 = pickle_filename_before_training\n",
    "\n",
    "objects_to_pickle_var_names_02.append('objects_to_pickle_var_names_02')\n",
    "objects_to_pickle_02.append(objects_to_pickle_var_names_02)\n",
    "\n",
    "with open(pickle_filename_02, 'wb') as pfh:\n",
    "    pickle.dump(objects_to_pickle_02 , pfh)\n",
    "##endof:  with open ... as pfh # (pickle file handle)\n",
    "\n",
    "pickle_filename_03 = \"lora_flan_t5_cpu_objects_03.pkl\" # will likely change\n",
    "objects_to_pickle_03 = []\n",
    "objects_to_pickle_var_names_03 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000e8490-6539-4c5c-b335-ac02c75122ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't need this again\n",
    "!powershell -c (Get-Date -UFormat \"%s_%Y-%m-%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98390317-475e-417b-be9e-9430cd7af826",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e62ce34-a826-4a83-8b2d-9acede4ff2a2",
   "metadata": {},
   "source": [
    "## Save the Trainer to Hugging Face and Get Our Updated Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a01a6f-b2c9-44b5-a8ff-86c7b6117fe1",
   "metadata": {},
   "source": [
    "### Commenting out the login to HuggingFace stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80265d1c-b65b-4863-8ac3-34e066c86522",
   "metadata": {},
   "outputs": [],
   "source": [
    "## # Don't need this again\n",
    "#!powershell -c (Get-Date -UFormat \"%s_%Y-%m-%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c105c8-8182-4c12-9ce6-1016ee4787c5",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e0693e-579b-4a82-a2c2-2d3dc1e6f900",
   "metadata": {},
   "source": [
    "I'm following the [(archived) tutorial from Mehul Gupta on Medium](https://web.archive.org/web/20240522140323/https://medium.com/data-science-in-your-pocket/lora-for-fine-tuning-llms-explained-with-codes-and-example-62a7ac5a3578); since it's archived, you can follow exactly what I'm doing.\n",
    "\n",
    "Running this next line of code will come up with a dialog box with text entry,\n",
    "and I'm now using the `@thebballdave025` for Hugging Face stuff.\n",
    "\n",
    "<b>Make sure to use the WRITE token, here.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e5a45e-1890-415c-9da3-9f43fa0969df",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  This will come up with a dialog box with text entry.\n",
    "##+ and I'm now using @thebballdave025 for Hugging Face.\n",
    "#\n",
    "## Use the write token, here.\n",
    "#notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c99a5c-2739-49f6-9a4b-02c087e4c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save tokenizer and create a tokenizer model card\n",
    "##taking out#tokenizer.save_pretrained('testing')\n",
    "#  #  'testing' is the local directory\n",
    "#\n",
    "## Create the trainer model card\n",
    "#trainer.create_model_card()\n",
    "#\n",
    "## Push the results to the Hugging Face Hub\n",
    "#trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c81523-7faf-40d9-806a-919038f6e6f1",
   "metadata": {},
   "source": [
    "## Actually Get the Model from Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b516e0d6-0f81-4bcb-8a73-d0eff0455fef",
   "metadata": {},
   "source": [
    "### Commenting out stuff from Hugging Face login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62333ba9-c416-4f04-b8ff-ff27be3a359b",
   "metadata": {},
   "source": [
    "Running this next line of code will come up with a dialog box with text entry,\n",
    "and I'm now using the `@thebballdave025` for Hugging Face stuff.\n",
    "\n",
    "<b>Make sure to use the READ token, here.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a022c0-760d-4fcb-bb71-a05e322598cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read token. Will bring up text entry to paste token string\n",
    "#notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207707c8-1920-446a-bfa9-9c8ee9480a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## # Don't need this again\n",
    "#!powershell -c (Get-Date -UFormat \"%s_%Y-%m-%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b4db3b-4516-4900-b640-ac498f0308bc",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e79207-23e2-4d73-ac6f-90a40a489574",
   "metadata": {},
   "source": [
    "(If you have problems that note `data_files` or `dataset` or `prompt_instruction_format`, make sure that the cells where these are defined have been run, i.e. the kernel hasn't been restarted since they were initialized.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90afd2a7-3eae-41b0-af3a-43a6041b474d",
   "metadata": {},
   "source": [
    "### Commenting out - Hugging Face Stuff from Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca447ad1-943e-420a-9898-8404fbb8b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "## My trained model from Hugging Face\n",
    "#\n",
    "#new_model_name = \"thebballdave025/dwb-flan-t5-small-lora-finetune-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d1a19-78ae-4e67-9125-ae81a0f4d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model_load_tic = timeit.default_timer()\n",
    "#new_model = AutoModelForSeq2SeqLM.from_pretrained(new_model_name)\n",
    "#new_model_load_toc = timeit.default_timer()\n",
    "#\n",
    "#new_model_load_duration = new_model_load_toc - new_model_load_tic\n",
    "#\n",
    "#print(f\"Loading the LoRA-fine-tuned model, {new_model_name}\")\n",
    "#print(f\"took {new_model_load_toc - new_model_load_tic:0.4f} seconds.\")\n",
    "#\n",
    "#new_model_load_time_str = format_timespan(new_model_load_duration)\n",
    "#\n",
    "#print(f\"which equates to {new_model_load_time_str}\")\n",
    "##\n",
    "##  Next line makes training faster but a little less accurate\n",
    "##+ but I'm not training it down here.\n",
    "##new_model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f764e-df00-4a08-a7de-64d92cd9358f",
   "metadata": {},
   "source": [
    "### New instead of commenting out - From Local Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e383569b-2785-4351-815a-4830c83a5e66",
   "metadata": {},
   "source": [
    "Starting the hopefully-fixed rest of it, now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f93408-37e8-426b-b08e-2c6421b0754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't need this again\n",
    "!powershell -c (Get-Date -UFormat \"%s_%Y-%m-%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8333fd1-6d90-47ce-9439-49611f1817f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = model_name ## = \"google/flan-t5-small\"\n",
    "adapter_model_name = \"output/checkpoint-1536\" # the path to the adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eaf257-69f2-448d-b531-c2218a12b8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = AutoModelForSeq2SeqLM.from_pretrained(base_model_name)\n",
    "# Below, note that `new_model` is a parameter. We're changing it.\n",
    "new_model = AutoPeftModelForCausalLM.from_pretrained(new_model, adapter_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1049946-ba6e-4623-b71b-23c1f4648235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  I'm saving it, but I don't know how important that will be.\n",
    "#+ I do know I won't use it in this notebook.\n",
    "#\n",
    "#  Reference:\n",
    "# ref=\"https://web.archive.org/web/20240628145441/\" + \\\n",
    "#     \"https://huggingface.co/docs/trl/main/en/use_model\"\n",
    "#> You can also merge the adapters into the base model \n",
    "#> so you can use the model like a normal transformers model, \n",
    "#> however the checkpoint will be significantly bigger\n",
    "#\n",
    "do_save_merged = False\n",
    "\n",
    "if do_save_merged:\n",
    "    new_model_2_save = new_model.merge_and_unload()\n",
    "    new_model_2_save.save_pretrained(\"merged_adapters\")\n",
    "##endof:  if do_save_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb6151-fd93-440b-b736-aea642f67ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_tokenizer = AutoTokenizer.from_pretrained(base_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc8db7f-873f-4feb-ab77-53d9c41351d2",
   "metadata": {},
   "source": [
    "#### Stuff for model architecture - post-LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8792fdf-eb40-4b73-b810-770227db7476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b45927-f379-40b8-bf9a-e18171037c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_arch_str = str(new_model)\n",
    "\n",
    "with open(\n",
    "  \"dwb-flan-t5-small-w-lora-finetune-2.model-architecture.txt\", \n",
    "  'w', \n",
    "  encoding='utf-8') as fhn:\n",
    "    fhn.write(new_model_arch_str)\n",
    "##endof:  with open ... fhn\n",
    "\n",
    "objects_to_pickle.append(base_model_name)\n",
    "objects_to_pickle_var_names.append('base_model_name')\n",
    "objects_to_pickle.append(adapter_model_name)\n",
    "objects_to_pickle_var_names.append('adapter_model_name')\n",
    "\n",
    "objects_to_pickle_03.append(base_model_name)\n",
    "objects_to_pickle_var_names_03.append('base_model_name')\n",
    "objects_to_pickle_03.append(adapter_model_name)\n",
    "objects_to_pickle_var_names_03.append('adapter_model_name')\n",
    "\n",
    "objects_to_pickle.append(new_model_arch_str)\n",
    "objects_to_pickle_var_names.append('new_model_arch_str')\n",
    "\n",
    "objects_to_pickle_03.append(new_model_arch_st)\n",
    "objects_to_pickle_var_names_03.append('new_model_arch_str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bd1c76-f3b8-44ff-8d6e-1b735155d546",
   "metadata": {},
   "source": [
    "@todo : get some Python version of `diff` going on here. I'm just using Cygwin/bash to see the LoRA additions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87701971-8342-470b-8f23-66f4494206e8",
   "metadata": {},
   "source": [
    "### Let's start by doing the single-dialogue summaries we used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c76d23-142f-4246-a34b-9ee1337b91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't need this again\n",
    "!powershell -c (Get-Date -UFormat \"%s_%Y-%m-%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ccc71-2e71-4fb1-a545-d9141a31bedc",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5d9936-59c4-447c-8dd5-343aebf66905",
   "metadata": {},
   "source": [
    "#### Note on the `tokenizer` parameter in the `pipline` function - minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee361379-7c1a-44f3-8b34-2189c785c05c",
   "metadata": {},
   "source": [
    "Note that in Guptal's example/tutorial, he did not give a `tokenizer` parameter to the `summarizer = pipeline` code. I haven't been able to get that working."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d8a8b-8a16-444f-8b78-4368d8f06846",
   "metadata": {},
   "source": [
    "#### Consistency in values of model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adaf306-dba1-4d93-8533-ac26fa689825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to keep it consistent, use these. If not, change them at will.\n",
    "model_to_use = new_model\n",
    "tokenizer_to_use = same_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70b7022-54f8-4efa-a8d6-16fe1c9a204f",
   "metadata": {},
   "source": [
    "#### Try one picked at random\n",
    "\n",
    "##### Well, not so randomly, anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4d5fed-163c-4886-8fbc-05b2307a028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_tat = pipeline('summarization', \n",
    "                          model=model_to_use,\n",
    "                          tokenizer=tokenizer_to_use\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35597fd8-f31a-483f-aa16-71ebda493cf8",
   "metadata": {},
   "source": [
    "There might be a warning with `The model 'PeftModelForCausalLM' is not supported for summarization. Supported models are` `...`. This is just about things not being officially integrated into the Transformer library.\n",
    "\n",
    "(\n",
    "  Full warning, for reference:\n",
    "\n",
    "    The model 'PeftModelForCausalLM' is not supported for summarization. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n",
    "\n",
    ")\n",
    "\n",
    "If the warning is there, it can safely be ignored. \n",
    "\n",
    "### (You don't need to spend 2 weeks trying to fix it, believing that all the warnings had been suppressed so it must be an error. You definitely shouldn't do that.)\n",
    "\n",
    "cf. https://web.archive.org/web/20240722220713/https://huggingface.co/tiiuae/falcon-40b/discussions/8\n",
    "\n",
    "> Sorry about the delay, the `The model 'RWForCausalLM'`\n",
    "\n",
    "ours says `The model 'PeftModelForCausalLM'`\n",
    "\n",
    "> `is not supported for text-generation.`\n",
    "\n",
    "ours says `is not supported for summarization.`\n",
    "\n",
    "> comes from the model not being integrated into the\n",
    "> core part of the transformers library yet. It's just\n",
    "> a warning, and generation should follow afterwards.\n",
    "\n",
    "hopefully this can be amended with \"and summarization should follow afterwards.\"\n",
    "\n",
    "##### OR\n",
    "\n",
    "https://web.archive.org/web/20240722220840/https://gist.github.com/ahoho/ba41c42984faf64bf4302b2b1cd7e0ce\n",
    "\n",
    "> I believe that is a just warning that you can safely ignore.\n",
    "> For the versions of transformers & PEFT I was using\n",
    "> (4.28.1 and 0.3.0.dev0, respectively), `PeftModelForCausalLM`\n",
    "\n",
    "(Our same model name)\n",
    "\n",
    "> had not been added to the text-generation\n",
    "\n",
    "(Hopefully everything is consistent if we replace 'text-generation' with 'summarization'.)\n",
    "\n",
    "> pipelines list of supported models (but, as you can see,\n",
    "> the underlying `LlamaForCausalLM`\n",
    "\n",
    "(For us, replace `LlamaForCausalLM` with `T5ForConditionalGeneration`)\n",
    "\n",
    "> upon which the Peft model\n",
    "> is added is supported--i.e., the warning is spurious)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7c8839-904d-484f-85b9-f7451b768476",
   "metadata": {},
   "source": [
    "Just one summarization to begin with, randomly picked ... but\n",
    "now with th possibility of a known seed, to allow visual \n",
    "comparison with after-training results.\n",
    "\n",
    "<strike>I'M NOT GOING TO USE THIS REPEATED SEED, I'm just going to\n",
    "use the datum at the first index to compare.</strike>\n",
    "\n",
    "User repeatability when sharing with Pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99bcc51-f9a4-41f0-b7bf-1d5398cac38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_seed_for_repeatable = True\n",
    "\n",
    "if do_seed_for_repeatable:\n",
    "    rand_seed_for_randrange = 137\n",
    "    random.seed(rand_seed_for_randrange)\n",
    "##endof:  if do_seed_for_repeatable\n",
    "\n",
    "sample = dataset['test'][randrange(len(dataset[\"test\"]))]\n",
    "print(f\"dialogue: \\n{sample['dialogue']}\\n---------------\")\n",
    "\n",
    "res = summarizer_tat(sample[\"dialogue\"])\n",
    "\n",
    "print(f\"dwb-flan-t5-small-w-lora-finetune-2 summary:\\n{res[0]['summary_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d88506-6e79-4d07-93f5-fa5ea9746d1b",
   "metadata": {},
   "source": [
    "#### Notes on investigations to fix weirdness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d339a1ed-41ef-4133-a37a-61f6b53c1931",
   "metadata": {},
   "source": [
    "@todo : format this more nicely\n",
    "\n",
    "```\n",
    "## Trials to fix weirdness.\n",
    "## model=old_model, tokenizer=old_tokenizer : matches baseline \n",
    "##                                            (quick)\n",
    "## model=new_model, tokenizer=new_tokenizer : weird results\n",
    "##                                            (takes significantly longer, too)\n",
    "## model=new_model, tokenizer=old_tokenizer : weird results\n",
    "##                                            (takes significantly longer, too)\n",
    "## model=old_model, tokenizer=new_tokenizer : actually matches baseline, which\n",
    "##                                            would seem to require a change in\n",
    "##                                            hypothesis as to why the\n",
    "##                                            weirdness and longer inference are\n",
    "##                                            happening. (Likely not tokenizer.)\n",
    "##                                            (quick)\n",
    "##\n",
    "##  I had thought that doing 'old_model' and 'new_tokenizer' gave me weird\n",
    "##+ results, too. Good thing to come back and check things.\n",
    "##  Still, the training results show the model was learning and improving.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121e7a31-de22-4dca-be9c-bff1f8705c45",
   "metadata": {},
   "source": [
    "#### Now, a couple summarizations with comparison to ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e1948-8eb4-41e2-84eb-be2cd71d9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_list = []\n",
    "ref_test_list = []\n",
    "\n",
    "sample_num = 0\n",
    "\n",
    "this_sample = dataset['test'][sample_num]\n",
    "\n",
    "print(f\"dialogue: \\n{this_sample['dialogue']}\\n---------------\")\n",
    "\n",
    "ground_summary = this_sample['summary']\n",
    "res = summarizer_tat(this_sample['dialogue'])\n",
    "res_summary = res[0]['summary_text']\n",
    "\n",
    "print(f\"human-genratd summary:\\n{ground_summary}\")\n",
    "print(f\"dwb-flan-t5-small-lora-finetune-2 summary:\\n{res_summary}\")\n",
    "\n",
    "ref_test_list.append(ground_summary)\n",
    "pred_test_list.append(res_summary)\n",
    "\n",
    "#  Yes, I have just one datum, but I'm setting things up to\n",
    "#+ work well with a loop (meaning lists for pred and ref).\n",
    "results_test_0 = compute_google_rouge_score(\n",
    "                            predictions=pred_test_list,\n",
    "                            references=ref_test_list,\n",
    "                            use_aggregator=False\n",
    ")\n",
    "\n",
    "# >>> print(list(results_test.keys()))\n",
    "# ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b13b61-4b8a-484f-b3c6-1128ec6f6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rouge_scores(results_test_0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fff7a1-ca74-4000-8fec-9d4ed1d011fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't want to aggregate, yet\n",
    "pred_test_list = []\n",
    "ref_test_list = []\n",
    "\n",
    "sample_num = 224\n",
    "\n",
    "this_sample = dataset['test'][sample_num]\n",
    "\n",
    "print(f\"dialogue: \\n{this_sample['dialogue']}\\n---------------\")\n",
    "\n",
    "ground_summary = this_sample['summary']\n",
    "res = summarizer_tat(this_sample['dialogue'])\n",
    "res_summary = res[0]['summary_text']\n",
    "\n",
    "print(f\"human-genratd summary:\\n{ground_summary}\")\n",
    "print(f\"dwb-flan-t5-small-lora-finetune-2:\\n{res_summary}\")\n",
    "\n",
    "ref_test_list.append(ground_summary)\n",
    "pred_test_list.append(res_summary)\n",
    "\n",
    "rouge = load_metric('rouge', trust_remote_code=True)\n",
    "\n",
    "results_test_224 = compute_google_rouge_score(\n",
    "                     predictions=pred_test_list,\n",
    "                     references=ref_test_list,\n",
    "                     use_aggregator=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bebf17-d3ca-46b7-afb3-941418ab36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rouge_scores(results_test_224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7160a6-d40d-43b0-a982-e944690e3e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't need this again\n",
    "!powershell -c (Get-Date -UFormat \"%s_%Y-%m-%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88281b15-7070-44dd-84e4-aedefa00293d",
   "metadata": {},
   "source": [
    "## Evaluation on the Test Set and Comparison to Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652d123c-412a-4195-8820-838590b814a2",
   "metadata": {},
   "source": [
    "#### Verbosity stuff - get rid of the nice advice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a7666e-206c-418a-aec8-27b0fd4de3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't need this again\n",
    "!powershell -c (Get-Date -UFormat \"%s_%Y-%m-%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f710cdea-0123-4f96-8f29-e2ea8144e318",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde59af6-c15a-4494-b49e-87019a70715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_verbosity_is_critical = \\\n",
    "  logging.get_verbosity() == logging.CRITICAL # alias FATAL, 50\n",
    "log_verbosity_is_error = \\\n",
    "  logging.get_verbosity() == logging.ERROR # 40\n",
    "log_verbosity_is_warn = \\\n",
    "  logging.get_verbosity() == logging.WARNING # alias WARN, 30\n",
    "log_verbosity_is_info = \\\n",
    "  logging.get_verbosity() == logging.INFO # 20\n",
    "log_verbosity_is_debug = \\\n",
    "  logging.get_verbosity() == logging.DEBUG # 10\n",
    "\n",
    "print( \"The statement, 'logging verbosity is CRITICAL' \" + \\\n",
    "      f\"is {log_verbosity_is_critical}\")\n",
    "print( \"The statement, 'logging verbosity is    ERROR' \" + \\\n",
    "      f\"is {log_verbosity_is_error}\")\n",
    "print( \"The statement, 'logging verbosity is  WARNING' \" + \\\n",
    "      f\"is {log_verbosity_is_warn}\")\n",
    "print( \"The statement, 'logging verbosity is     INFO' \" + \\\n",
    "      f\"is {log_verbosity_is_info}\")\n",
    "print( \"The statement, 'logging verbosity is    DEBUG' \" + \\\n",
    "      f\"is {log_verbosity_is_debug}\")\n",
    "\n",
    "print()\n",
    "\n",
    "init_log_verbosity = logging.get_verbosity()\n",
    "print(f\"The value of logging.get_verbosity() is: {init_log_verbosity}\")\n",
    "\n",
    "print()\n",
    "\n",
    "init_t_n_a_w = os.environ.get('TRANSFORMERS_NO_ADVISORY_WARNINGS')\n",
    "print(f\"TRANSFORMERS_NO_ADIVSORY_WARNINGS: {init_t_n_a_w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf8db54-8003-429f-8abd-cfb09a1af80b",
   "metadata": {},
   "source": [
    "### Here's the actual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52d3eeb-e238-43bf-ada2-3d7ccaf10b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't need this again\n",
    "!powershell -c (Get-Date -UFormat \"%s_%Y-%m-%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d0f187-2402-44a4-8322-f899df42fab4",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a522d7-6285-4b9d-b619-ea0f454f2cae",
   "metadata": {},
   "source": [
    "<b>!!! NOTE !!!</b> I'm going to use `tat` (with an underscore\n",
    "or undescores before, after, or surrounding the variable names)\n",
    "to indicate 'testing-after-training'.\n",
    "\n",
    "I guess I could have used `inference`, but I didn't."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523785e0-4ece-49cc-bb8a-64d7c3b0bb01",
   "metadata": {},
   "source": [
    "<b>!!! another NOTE</b> You'd better <b>make \n",
    "dang sure you want the lots of output</b> \n",
    "before you set this next boolean to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a638f1-5abb-4c3e-8683-dcc49557a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_have_lotta_output_from_all_dialogs_summaries_2 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdfd04c-675b-4e8c-b293-560617b5651a",
   "metadata": {},
   "source": [
    "# Are you sure about the value of that last boolean? 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9357f5e1-a59c-4b4e-a374-fbd47d341546",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"That last boolean has the value:\")\n",
    "print(f\"{do_have_lotta_output_from_all_dialogs_summaries_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec12c114-8f82-4cbd-aef3-fa1b5c8c237b",
   "metadata": {},
   "source": [
    "There could be up to megabytes worth of text output if you've changed it to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1ad3bd-0921-4753-8c6c-175bffc23b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_error()\n",
    "\n",
    "tat_summarizer = summarizer_tat\n",
    "\n",
    "tat_sample_dialog_list = []\n",
    "prediction_tat_list = []\n",
    "reference_tat_list = []\n",
    "\n",
    "tat_tic = timeit.default_timer()\n",
    "\n",
    "for sample_num in range(len(dataset['test'])):\n",
    "    this_sample = dataset['test'][sample_num]\n",
    "    \n",
    "    if do_have_lotta_output_from_all_dialogs_summaries_2:\n",
    "        print(\"=\"*75)\n",
    "        print(f\"dialogue: \\n{this_sample['dialogue']}\\n---------------\")\n",
    "    ##endof:  if do_have_lotta_output_from_all_dialogs_summaries_2\n",
    "    \n",
    "    ground_tat_summary = this_sample['summary']\n",
    "    res_tat = tat_summarizer(this_sample['dialogue'])\n",
    "    res_tat_summary = res_tat[0]['summary_text']\n",
    "    \n",
    "    if do_have_lotta_output_from_all_dialogs_summaries_2:\n",
    "        print(\"-\"*70)\n",
    "        print(f\"human-genratd summary:\\n{ground_tat_summary}\")\n",
    "        print(\"-\"*70)\n",
    "        print(f\"flan-t5-small summary:\\n{res_tat_summary}\")\n",
    "        print(\"-\"*70)\n",
    "    ##endof:  if do_have_lotta_output_from_all_dialogs_summaries_2\n",
    "\n",
    "    tat_sample_dialog_list.append(this_sample['dialogue'])\n",
    "    reference_tat_list.append(ground_tat_summary)\n",
    "    prediction_tat_list.append(res_tat_summary)\n",
    "##endof:  for sample_num in range(len(dataset['test']))\n",
    "\n",
    "tat_toc = timeit.default_timer()\n",
    "\n",
    "tat_duration = tat_toc = tat_tic\n",
    "\n",
    "print( \"Getting things ready for scoring (after training)\")\n",
    "print(f\"took {tat_toc - tat_tic:0.4f} seconds.\")\n",
    "\n",
    "tat_time_str = format_timespan(tat_duration)\n",
    "\n",
    "print(f\"which equates to {tat_time_str}\")\n",
    "\n",
    "rouge = load_metric('rouge', trust_remote_code=True)\n",
    "\n",
    "results_tat = compute_google_rouge_score(\n",
    "                  predictions=prediction_tat_list,\n",
    "                  references=reference_tat_list,\n",
    "                  use_aggregator=True\n",
    ")\n",
    "\n",
    "# >>> print(list(results_tat.keys()))\n",
    "# ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
    "\n",
    "objects_to_pickle.append(tat_sample_dialog_list)\n",
    "objects_to_pickle_var_names.append('tat_sample_dialog_list')\n",
    "objects_to_pickle.append(prediction_tat_list)\n",
    "objects_to_pickle_var_names.append('prediction_tat_list')\n",
    "objects_to_pickle.append(reference_tat_list)\n",
    "objects_to_pickle_var_names.append('reference_tat_list')\n",
    "objects_to_pickle.append(results_tat)\n",
    "objects_to_pickle_var_names.append('results_tat')\n",
    "\n",
    "#incremental\n",
    "objects_to_pickle_03.append(tat_sample_dialog_list)\n",
    "objects_to_pickle_var_names_03.append('tat_sample_dialog_list')\n",
    "objects_to_pickle_03.append(prediction_tat_list)\n",
    "objects_to_pickle_var_names_03.append('prediction_tat_list')\n",
    "objects_to_pickle_03.append(reference_tat_list)\n",
    "objects_to_pickle_var_names_03.append('reference_tat_list')\n",
    "objects_to_pickle_03.append(results_tat)\n",
    "objects_to_pickle_var_names_03.append('results_tat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e708b7-ab43-4610-9e7c-f7b7ae2fd188",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Haven't tried this, because the logging seemed easier,\n",
    "##+ and the logging worked\n",
    "# os.environ(\"TRANSFORMERS_NO_ADVISORY_WARNINGS\") = init_t_n_a_w\n",
    "\n",
    "logging.set_verbosity(init_log_verbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc2b004-b8af-4213-b406-cab89cd98466",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rouge_scores(results_tat, \"TEST AFTER TRAINING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc962cc0-a916-4747-9950-794c6e0582c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't need this again\n",
    "!powershell -c (Get-Date -UFormat \"%s_%Y-%m-%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088562e2-4c61-4d4f-b4c6-6583adaf5a08",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f33df-d2fb-48e8-b6c0-e0f3d2d84b21",
   "metadata": {},
   "source": [
    "### Any comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02621ea6-f47d-4910-bf5a-966b2ac0c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any comparison code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d6c25f-222f-4bf2-9c09-f128c18758c1",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb63f34-c6d8-4a64-8712-99137b5a9ddb",
   "metadata": {},
   "source": [
    "## A Saving Checkpoint - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a70d66-c97f-4cd5-83f6-d76b1a60ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#incremental\n",
    "pickle_filename_after_lora_test = \"lora_flan_t5_cpu_objects_-_03_after_lora_test.pkl\"\n",
    "pickle_filename_03 = pickle_filename_before_training\n",
    "\n",
    "objects_to_pickle_var_names_03.append('objects_to_pickle_var_names_03')\n",
    "objects_to_pickle_03.append(objects_to_pickle_var_names_03)\n",
    "\n",
    "with open(pickle_filename_03, 'wb') as pfh:\n",
    "    pickle.dump(objects_to_pickle_03 , pfh)\n",
    "##endof:  with open ... as pfh # (pickle file handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c85f4f-2a67-4362-937d-330d2f49185a",
   "metadata": {},
   "source": [
    "## Now, ALL Pickle things to pickle save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5526ab-3d35-4b79-a18a-0cca17e5f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_to_pickle_var_names.append('objects_to_pickle_var_names')\n",
    "\n",
    "objects_to_pickle.append(objects_to_pickle_var_names)\n",
    "\n",
    "with open(pickle_filename, 'wb') as pfh:\n",
    "    pickle.dump(objects_to_pickle , pfh)\n",
    "##endof:  with open ... as pfh # (pickle file handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb8a2b-b210-47ba-ba52-9e861171b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't need this again\n",
    "!powershell -c (Get-Date -UFormat \"%s_%Y-%m-%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09df8629-a529-4240-ae31-ec9122b04c65",
   "metadata": {},
   "source": [
    "Output was:\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5af6893-b04d-42d1-8694-aeca3b33f993",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64861a7-2957-4381-b8c1-9ade6b7b0563",
   "metadata": {},
   "source": [
    "## Notes Looking Forward to LoRA on RWKV - minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66346d54-06bb-47da-8d54-a9dee43b408a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Hugging Face Community, seems to have a good portion of their models\n",
    "\n",
    "https://huggingface.co/RWKV\n",
    "\n",
    "https://web.archive.org/web/20240530232509/https://huggingface.co/RWKV\n",
    "\n",
    "<br/>\n",
    "\n",
    "GitHub has even more versions/models, including the `v4-neo` that\n",
    "I think will be important (the LoRA project)\n",
    "\n",
    "https://github.com/BlinkDL/RWKV-LM/tree/main\n",
    "\n",
    "https://web.archive.org/web/20240530232637/https://github.com/BlinkDL/RWKV-LM/tree/main\n",
    "\n",
    "<br/>\n",
    "\n",
    "The main RWKV website (?!)\n",
    "\n",
    "https://www.rwkv.com/\n",
    "\n",
    "https://web.archive.org/web/20240529120904/https://www.rwkv.com/\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "GOOD STUFF. A project doing LoRA with RWKV\n",
    "\n",
    "https://github.com/Blealtan/RWKV-LM-LoRA/\n",
    "\n",
    "https://web.archive.org/web/20240530232823/https://github.com/Blealtan/RWKV-LM-LoRA\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "The official blog, I guess, with some good coding examples\n",
    "\n",
    "https://huggingface.co/blog/rwkv\n",
    "\n",
    "https://web.archive.org/web/20240530233025/https://huggingface.co/blog/rwkv\n",
    "\n",
    "It includes something that's similar to what I'm doing here in the\n",
    "`First_Full_LoRA_Trial_with_Transformer_Again.ipynb` tutorial, etc.\n",
    "\n",
    "```\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"RWKV/rwkv-raven-1b5\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(0)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "```\n",
    "\n",
    "The `AutoModelForCausalLM` is the same as the tutorial I'm following,\n",
    "but I don't know what the `.to(0)` is for.\n",
    "\n",
    "Really quickly, also looking at\n",
    "\n",
    "https://huggingface.co/RWKV/rwkv-4-world-7b\n",
    "\n",
    "https://web.archive.org/web/20240530234438/https://huggingface.co/RWKV/rwkv-4-world-7b\n",
    "\n",
    "I see an example for CPU.\n",
    "\n",
    "```\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "              \"RWKV/rwkv-4-world-7b\",\n",
    "              trust_remote_code=True\n",
    ").to(torch.float32)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "              \"RWKV/rwkv-4-world-7b\",\n",
    "              trust_remote_code=True)\n",
    "```\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "(Old version? Unofficial, it seems)\n",
    "\n",
    "https://huggingface.co/docs/transformers/en/model_doc/rwkv\n",
    "\n",
    "https://web.archive.org/web/20240530232341/https://huggingface.co/docs/transformers/en/model_doc/rwkv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
