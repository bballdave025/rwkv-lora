{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.23832221163012393,
  "eval_steps": 250,
  "global_step": 250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0009532888465204957,
      "grad_norm": 0.307153582572937,
      "learning_rate": 0.00019980934223069591,
      "loss": 2.7623,
      "step": 1
    },
    {
      "epoch": 0.004766444232602479,
      "grad_norm": 0.36438095569610596,
      "learning_rate": 0.0001990467111534795,
      "loss": 2.7967,
      "step": 5
    },
    {
      "epoch": 0.009532888465204958,
      "grad_norm": 0.5419382452964783,
      "learning_rate": 0.00019809342230695903,
      "loss": 2.6901,
      "step": 10
    },
    {
      "epoch": 0.014299332697807437,
      "grad_norm": 0.6505125761032104,
      "learning_rate": 0.0001971401334604385,
      "loss": 2.3337,
      "step": 15
    },
    {
      "epoch": 0.019065776930409915,
      "grad_norm": 0.6815025806427002,
      "learning_rate": 0.00019618684461391803,
      "loss": 2.1854,
      "step": 20
    },
    {
      "epoch": 0.023832221163012392,
      "grad_norm": 0.47881466150283813,
      "learning_rate": 0.00019523355576739752,
      "loss": 1.9753,
      "step": 25
    },
    {
      "epoch": 0.028598665395614873,
      "grad_norm": 0.5425577759742737,
      "learning_rate": 0.00019428026692087705,
      "loss": 1.7498,
      "step": 30
    },
    {
      "epoch": 0.03336510962821735,
      "grad_norm": 0.44173935055732727,
      "learning_rate": 0.00019332697807435654,
      "loss": 1.4839,
      "step": 35
    },
    {
      "epoch": 0.03813155386081983,
      "grad_norm": 0.43801501393318176,
      "learning_rate": 0.00019237368922783604,
      "loss": 1.3203,
      "step": 40
    },
    {
      "epoch": 0.042897998093422304,
      "grad_norm": 0.36845311522483826,
      "learning_rate": 0.00019142040038131554,
      "loss": 1.0272,
      "step": 45
    },
    {
      "epoch": 0.047664442326024785,
      "grad_norm": 0.38564759492874146,
      "learning_rate": 0.00019046711153479506,
      "loss": 0.9353,
      "step": 50
    },
    {
      "epoch": 0.052430886558627265,
      "grad_norm": 0.28672581911087036,
      "learning_rate": 0.00018951382268827456,
      "loss": 0.7365,
      "step": 55
    },
    {
      "epoch": 0.057197330791229746,
      "grad_norm": 0.3096940815448761,
      "learning_rate": 0.00018856053384175406,
      "loss": 0.6141,
      "step": 60
    },
    {
      "epoch": 0.06196377502383222,
      "grad_norm": 0.2108839601278305,
      "learning_rate": 0.00018760724499523355,
      "loss": 0.5234,
      "step": 65
    },
    {
      "epoch": 0.0667302192564347,
      "grad_norm": 0.17616945505142212,
      "learning_rate": 0.00018665395614871305,
      "loss": 0.4497,
      "step": 70
    },
    {
      "epoch": 0.07149666348903717,
      "grad_norm": 0.17396551370620728,
      "learning_rate": 0.00018570066730219258,
      "loss": 0.4387,
      "step": 75
    },
    {
      "epoch": 0.07626310772163966,
      "grad_norm": 0.16254766285419464,
      "learning_rate": 0.00018474737845567207,
      "loss": 0.3736,
      "step": 80
    },
    {
      "epoch": 0.08102955195424213,
      "grad_norm": 0.13059984147548676,
      "learning_rate": 0.0001837940896091516,
      "loss": 0.3412,
      "step": 85
    },
    {
      "epoch": 0.08579599618684461,
      "grad_norm": 0.1389453411102295,
      "learning_rate": 0.0001828408007626311,
      "loss": 0.3306,
      "step": 90
    },
    {
      "epoch": 0.0905624404194471,
      "grad_norm": 0.12244414538145065,
      "learning_rate": 0.0001818875119161106,
      "loss": 0.3064,
      "step": 95
    },
    {
      "epoch": 0.09532888465204957,
      "grad_norm": 0.12522269785404205,
      "learning_rate": 0.0001809342230695901,
      "loss": 0.3067,
      "step": 100
    },
    {
      "epoch": 0.10009532888465204,
      "grad_norm": 0.11474015563726425,
      "learning_rate": 0.0001799809342230696,
      "loss": 0.2625,
      "step": 105
    },
    {
      "epoch": 0.10486177311725453,
      "grad_norm": 0.13086295127868652,
      "learning_rate": 0.0001790276453765491,
      "loss": 0.271,
      "step": 110
    },
    {
      "epoch": 0.109628217349857,
      "grad_norm": 0.11956343054771423,
      "learning_rate": 0.0001780743565300286,
      "loss": 0.2525,
      "step": 115
    },
    {
      "epoch": 0.11439466158245949,
      "grad_norm": 0.13015320897102356,
      "learning_rate": 0.0001771210676835081,
      "loss": 0.2535,
      "step": 120
    },
    {
      "epoch": 0.11916110581506197,
      "grad_norm": 0.1198173314332962,
      "learning_rate": 0.0001761677788369876,
      "loss": 0.2615,
      "step": 125
    },
    {
      "epoch": 0.12392755004766444,
      "grad_norm": 0.10572207719087601,
      "learning_rate": 0.00017521448999046713,
      "loss": 0.2457,
      "step": 130
    },
    {
      "epoch": 0.12869399428026693,
      "grad_norm": 0.08601856231689453,
      "learning_rate": 0.00017426120114394662,
      "loss": 0.2422,
      "step": 135
    },
    {
      "epoch": 0.1334604385128694,
      "grad_norm": 0.10068266838788986,
      "learning_rate": 0.00017330791229742615,
      "loss": 0.2333,
      "step": 140
    },
    {
      "epoch": 0.13822688274547187,
      "grad_norm": 0.09995309263467789,
      "learning_rate": 0.00017235462345090562,
      "loss": 0.2359,
      "step": 145
    },
    {
      "epoch": 0.14299332697807435,
      "grad_norm": 0.10637041181325912,
      "learning_rate": 0.00017140133460438514,
      "loss": 0.2292,
      "step": 150
    },
    {
      "epoch": 0.14775977121067682,
      "grad_norm": 0.1177048608660698,
      "learning_rate": 0.00017044804575786464,
      "loss": 0.2133,
      "step": 155
    },
    {
      "epoch": 0.15252621544327932,
      "grad_norm": 0.09634800255298615,
      "learning_rate": 0.00016949475691134416,
      "loss": 0.2143,
      "step": 160
    },
    {
      "epoch": 0.1572926596758818,
      "grad_norm": 0.09355175495147705,
      "learning_rate": 0.00016854146806482366,
      "loss": 0.2139,
      "step": 165
    },
    {
      "epoch": 0.16205910390848427,
      "grad_norm": 0.42484909296035767,
      "learning_rate": 0.00016758817921830313,
      "loss": 0.2069,
      "step": 170
    },
    {
      "epoch": 0.16682554814108674,
      "grad_norm": 0.1165904626250267,
      "learning_rate": 0.00016663489037178265,
      "loss": 0.1984,
      "step": 175
    },
    {
      "epoch": 0.17159199237368922,
      "grad_norm": 0.09310045093297958,
      "learning_rate": 0.00016568160152526215,
      "loss": 0.1941,
      "step": 180
    },
    {
      "epoch": 0.17635843660629172,
      "grad_norm": 0.12128669023513794,
      "learning_rate": 0.00016472831267874168,
      "loss": 0.188,
      "step": 185
    },
    {
      "epoch": 0.1811248808388942,
      "grad_norm": 0.0815657377243042,
      "learning_rate": 0.00016377502383222117,
      "loss": 0.184,
      "step": 190
    },
    {
      "epoch": 0.18589132507149667,
      "grad_norm": 0.09277266263961792,
      "learning_rate": 0.00016282173498570067,
      "loss": 0.1871,
      "step": 195
    },
    {
      "epoch": 0.19065776930409914,
      "grad_norm": 0.10186007618904114,
      "learning_rate": 0.00016186844613918017,
      "loss": 0.1786,
      "step": 200
    },
    {
      "epoch": 0.1954242135367016,
      "grad_norm": 0.08006875216960907,
      "learning_rate": 0.0001609151572926597,
      "loss": 0.1758,
      "step": 205
    },
    {
      "epoch": 0.2001906577693041,
      "grad_norm": 0.09366367757320404,
      "learning_rate": 0.0001599618684461392,
      "loss": 0.1788,
      "step": 210
    },
    {
      "epoch": 0.2049571020019066,
      "grad_norm": 0.08705569058656693,
      "learning_rate": 0.0001590085795996187,
      "loss": 0.1705,
      "step": 215
    },
    {
      "epoch": 0.20972354623450906,
      "grad_norm": 0.11188893765211105,
      "learning_rate": 0.00015805529075309818,
      "loss": 0.1718,
      "step": 220
    },
    {
      "epoch": 0.21448999046711154,
      "grad_norm": 0.08841504156589508,
      "learning_rate": 0.0001571020019065777,
      "loss": 0.1677,
      "step": 225
    },
    {
      "epoch": 0.219256434699714,
      "grad_norm": 0.1058618426322937,
      "learning_rate": 0.0001561487130600572,
      "loss": 0.1679,
      "step": 230
    },
    {
      "epoch": 0.22402287893231648,
      "grad_norm": 0.09331177175045013,
      "learning_rate": 0.0001551954242135367,
      "loss": 0.1613,
      "step": 235
    },
    {
      "epoch": 0.22878932316491898,
      "grad_norm": 0.09750111401081085,
      "learning_rate": 0.00015424213536701623,
      "loss": 0.1602,
      "step": 240
    },
    {
      "epoch": 0.23355576739752146,
      "grad_norm": 0.10616492480039597,
      "learning_rate": 0.00015328884652049572,
      "loss": 0.1758,
      "step": 245
    },
    {
      "epoch": 0.23832221163012393,
      "grad_norm": 0.09010384231805801,
      "learning_rate": 0.00015233555767397522,
      "loss": 0.1609,
      "step": 250
    },
    {
      "epoch": 0.23832221163012393,
      "eval_loss": 0.057427018880844116,
      "eval_runtime": 301.1636,
      "eval_samples_per_second": 0.757,
      "eval_steps_per_second": 0.189,
      "step": 250
    }
  ],
  "logging_steps": 5,
  "max_steps": 1049,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 250,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 284686848000000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
